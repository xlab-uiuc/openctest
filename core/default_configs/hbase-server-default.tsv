hbase.rootdir   ${hbase.tmp.dir}/hbase	The directory shared by region servers and into     which HBase persists.  The URL should be 'fully-qualified'     to include the filesystem scheme.  For example, to specify the     HDFS directory '/hbase' where the HDFS instance's namenode is     running at namenode.example.org on port 9000, set this value to:     hdfs://namenode.example.org:9000/hbase.  By default, we write     to whatever ${hbase.tmp.dir} is set too -- usually /tmp --     so change this configuration or else all data will be lost on     machine restart.
zookeeper.recovery.retry.maxsleeptime	60000	Max sleep time before retry zookeeper operations in milliseconds,     a max time is needed here so that sleep time won't grow unboundedly
hbase.master.port	16000	The port the HBase Master should bind to.
hbase.master.info.bindAddress	0.0.0.0	The bind address for the HBase Master web UI
hbase.master.logcleaner.plugins	org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner,org.apache.hadoop.hbase.master.cleaner.TimeToLiveProcedureWALCleaner	A comma-separated list of BaseLogCleanerDelegate invoked by     the LogsCleaner service. These WAL cleaners are called in order,     so put the cleaner that prunes the most files in front. To     implement your own BaseLogCleanerDelegate, just put it in HBase's classpath     and add the fully qualified class name here. Always add the above     default log cleaners in the list.
hbase.master.logcleaner.ttl	600000	How long a WAL remain in the archive ({hbase.rootdir}/oldWALs) directory,     after which it will be cleaned by a Master thread. The value is in milliseconds.
hbase.regionserver.port	16020	The port the HBase RegionServer binds to.
hbase.regionserver.info.port	16030	The port for the HBase RegionServer web UI     Set to -1 if you do not want the RegionServer UI to run.
hbase.regionserver.info.bindAddress	0.0.0.0	The address for the HBase RegionServer web UI
hbase.regionserver.handler.count	30	Count of RPC Listener instances spun up on RegionServers.       Same property is used by the Master for count of master handlers.       Too many handlers can be counter-productive. Make it a multiple of       CPU count. If mostly read-only, handlers count close to cpu count       does well. Start with twice the CPU count and tune from there.
hbase.ipc.server.callqueue.read.ratio	0	Split the call queues into read and write queues.       The specified interval (which should be between 0.0 and 1.0)       will be multiplied by the number of call queues.       A value of 0 indicate to not split the call queues, meaning that both read and write       requests will be pushed to the same set of queues.       A value lower than 0.5 means that there will be less read queues than write queues.       A value of 0.5 means there will be the same number of read and write queues.       A value greater than 0.5 means that there will be more read queues than write queues.       A value of 1.0 means that all the queues except one are used to dispatch read requests.        Example: Given the total number of call queues being 10       a read.ratio of 0 means that: the 10 queues will contain both read/write requests.       a read.ratio of 0.3 means that: 3 queues will contain only read requests       and 7 queues will contain only write requests.       a read.ratio of 0.5 means that: 5 queues will contain only read requests       and 5 queues will contain only write requests.       a read.ratio of 0.8 means that: 8 queues will contain only read requests       and 2 queues will contain only write requests.       a read.ratio of 1 means that: 9 queues will contain only read requests       and 1 queues will contain only write requests.
hbase.regionserver.logroll.period	3600000	Period at which we will roll the commit log regardless     of how many edits it has.
hbase.regionserver.logroll.errors.tolerated	2	The number of consecutive WAL close errors we will allow     before triggering a server abort.  A setting of 0 will cause the     region server to abort if closing the current WAL writer fails during     log rolling.  Even a small value (2 or 3) will allow a region server     to ride over transient HDFS errors.
hbase.regionserver.hlog.reader.impl	org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader	The WAL file reader implementation.
hbase.regionserver.hlog.writer.impl	org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter	The WAL file writer implementation.
hbase.regionserver.global.memstore.size		Maximum size of all memstores in a region server before new       updates are blocked and flushes are forced. Defaults to 40% of heap (0.4).       Updates are blocked and flushes are forced until size of all memstores       in a region server hits hbase.regionserver.global.memstore.size.lower.limit.       The default value in this configuration has been intentionally left empty in order to       honor the old hbase.regionserver.global.memstore.upperLimit property if present.
hbase.regionserver.global.memstore.size.lower.limit		Maximum size of all memstores in a region server before flushes       are forced. Defaults to 95% of hbase.regionserver.global.memstore.size       (0.95). A 100% value for this value causes the minimum possible flushing       to occur when updates are blocked due to memstore limiting. The default       value in this configuration has been intentionally left empty in order to       honor the old hbase.regionserver.global.memstore.lowerLimit property if       present.
hbase.systemtables.compacting.memstore.type	NONE	Determines the type of memstore to be used for system tables like       META, namespace tables etc. By default NONE is the type and hence we use the       default memstore for all the system tables. If we need to use compacting       memstore for system tables then set this property to BASIC/EAGER
hbase.regionserver.optionalcacheflushinterval	3600000	Maximum amount of time an edit lives in memory before being automatically flushed.     Default 1 hour. Set it to 0 to disable automatic flushing.
hbase.regionserver.dns.nameserver	default	The host name or IP address of the name server (DNS)       which a region server should use to determine the host name used by the       master for communication and display purposes.
hbase.regionserver.regionSplitLimit	1000	Limit for the number of regions after which no more region splitting       should take place. This is not hard limit for the number of regions       but acts as a guideline for the regionserver to stop splitting after       a certain limit. Default is set to 1000.
zookeeper.session.timeout	90000	ZooKeeper session timeout in milliseconds. It is used in two different ways.       First, this value is used in the ZK client that HBase uses to connect to the ensemble.       It is also used by HBase when it starts a ZK server and it is passed as the 'maxSessionTimeout'.       See https://zookeeper.apache.org/doc/current/zookeeperProgrammers.html#ch_zkSessions.       For example, if an HBase region server connects to a ZK ensemble that's also managed       by HBase, then the session timeout will be the one specified by this configuration.       But, a region server that connects to an ensemble managed with a different configuration       will be subjected that ensemble's maxSessionTimeout. So, even though HBase might propose       using 90 seconds, the ensemble can have a max timeout lower than this and it will take       precedence. The current default maxSessionTimeout that ZK ships with is 40 seconds, which is lower than       HBase's.
zookeeper.znode.parent	/hbase	Root ZNode for HBase in ZooKeeper. All of HBase's ZooKeeper       files that are configured with a relative path will go under this node.       By default, all of HBase's ZooKeeper file paths are configured with a       relative path, so they will all go under this directory unless changed.
zookeeper.znode.acl.parent	acl	Root ZNode for access control lists.
hbase.zookeeper.property.clientPort	2181	Property from ZooKeeper's config zoo.cfg.     The port at which the clients will connect.
hbase.client.pause.cqtbe		Whether or not to use a special client pause for     CallQueueTooBigException (cqtbe). Set this property to a higher value     than hbase.client.pause if you observe frequent CQTBE from the same     RegionServer and the call queue there keeps full
hbase.client.retries.number	15	Maximum retries.  Used as maximum for all retryable     operations such as the getting of a cell's value, starting a row update,     etc.  Retry interval is a rough function based on hbase.client.pause.  At     first we retry at this interval but then with backoff, we pretty quickly reach     retrying every ten seconds.  See HConstants#RETRY_BACKOFF for how the backup     ramps up.  Change this setting and hbase.client.pause to suit your workload.
hbase.client.max.total.tasks	100	The maximum number of concurrent mutation tasks a single HTable instance will     send to the cluster.
hbase.client.keyvalue.maxsize	10485760	Specifies the combined maximum allowed size of a KeyValue     instance. This is to set an upper boundary for a single entry saved in a     storage file. Since they cannot be split it helps avoiding that a region     cannot be split any further because the data is too large. It seems wise     to set this to a fraction of the maximum region size. Setting it to zero     or less disables the check.
hbase.bulkload.retries.number	10	Maximum retries.  This is maximum number of iterations     to atomic bulk loads are attempted in the face of splitting operations     0 means never give up.
hbase.regions.slop	0.001	Rebalance if any regionserver has average + (average * slop) regions.       The default value of this parameter is 0.001 in StochasticLoadBalancer (the default load balancer),       while the default is 0.2 in other load balancers (i.e., SimpleLoadBalancer).
hbase.server.thread.wakefrequency	10000	Time to sleep in between searches for work (in milliseconds).     Used as sleep interval by service threads such as log roller.
hbase.server.versionfile.writeattempts	3	How many times to retry attempting to write a version file     before just aborting. Each attempt is separated by the     hbase.server.thread.wakefrequency milliseconds.
hbase.hregion.memstore.flush.size	134217728	Memstore will be flushed to disk if size of the memstore     exceeds this number of bytes.  Value is checked by a thread that runs     every hbase.server.thread.wakefrequency.
hbase.hregion.percolumnfamilyflush.size.lower.bound.min	16777216	If FlushLargeStoresPolicy is used and there are multiple column families,     then every time that we hit the total memstore limit, we find out all the     column families whose memstores exceed a "lower bound" and only flush them     while retaining the others in memory. The "lower bound" will be     "hbase.hregion.memstore.flush.size / column_family_number" by default     unless value of this property is larger than that. If none of the families     have their memstore size more than lower bound, all the memstores will be     flushed (just as usual).
hbase.hregion.memstore.block.multiplier	4	Block updates if memstore has hbase.hregion.memstore.block.multiplier     times hbase.hregion.memstore.flush.size bytes.  Useful preventing     runaway memstore during spikes in update traffic.  Without an     upper-bound, memstore fills such that when it flushes the     resultant flush files take a long time to compact or split, or     worse, we OOME.
hbase.hregion.majorcompaction	604800000	Time between major compactions, expressed in milliseconds. Set to 0 to disable       time-based automatic major compactions. User-requested and size-based major compactions will       still run. This value is multiplied by hbase.hregion.majorcompaction.jitter to cause       compaction to start at a somewhat-random time during a given window of time. The default value       is 7 days, expressed in milliseconds. If major compactions are causing disruption in your       environment, you can configure them to run at off-peak times for your deployment, or disable       time-based major compactions by setting this parameter to 0, and run major compactions in a       cron job or by another external mechanism.
hbase.hstore.compactionThreshold	3	If more than this number of StoreFiles exist in any one Store       (one StoreFile is written per flush of MemStore), a compaction is run to rewrite all       StoreFiles into a single StoreFile. Larger values delay compaction, but when compaction does       occur, it takes longer to complete.
hbase.regionserver.compaction.enabled	true	Enable/disable compactions on by setting true/false.       We can further switch compactions dynamically with the       compaction_switch shell command.
hbase.hstore.flusher.count	2	The number of flush threads. With fewer threads, the MemStore flushes will be       queued. With more threads, the flushes will be executed in parallel, increasing the load on       HDFS, and potentially causing more compactions.
hbase.hstore.blockingStoreFiles	16	If more than this number of StoreFiles exist in any one Store (one StoreFile      is written per flush of MemStore), updates are blocked for this region until a compaction is       completed, or until hbase.hstore.blockingWaitTime has been exceeded.
hbase.hstore.compaction.min	3	The minimum number of StoreFiles which must be eligible for compaction before       compaction can run. The goal of tuning hbase.hstore.compaction.min is to avoid ending up with       too many tiny StoreFiles to compact. Setting this value to 2 would cause a minor compaction       each time you have two StoreFiles in a Store, and this is probably not appropriate. If you       set this value too high, all the other values will need to be adjusted accordingly. For most       cases, the default value is appropriate. In previous versions of HBase, the parameter       hbase.hstore.compaction.min was named hbase.hstore.compactionThreshold.
hbase.hstore.compaction.max	10	The maximum number of StoreFiles which will be selected for a single minor       compaction, regardless of the number of eligible StoreFiles. Effectively, the value of       hbase.hstore.compaction.max controls the length of time it takes a single compaction to       complete. Setting it larger means that more StoreFiles are included in a compaction. For most       cases, the default value is appropriate.
hbase.hstore.compaction.min.size	134217728	A StoreFile (or a selection of StoreFiles, when using ExploringCompactionPolicy)       smaller than this size will always be eligible for minor compaction.       HFiles this size or larger are evaluated by hbase.hstore.compaction.ratio to determine if       they are eligible. Because this limit represents the "automatic include" limit for all       StoreFiles smaller than this value, this value may need to be reduced in write-heavy       environments where many StoreFiles in the 1-2 MB range are being flushed, because every       StoreFile will be targeted for compaction and the resulting StoreFiles may still be under the       minimum size and require further compaction. If this parameter is lowered, the ratio check is       triggered more quickly. This addressed some issues seen in earlier versions of HBase but       changing this parameter is no longer necessary in most situations. Default: 128 MB expressed       in bytes.
hbase.hstore.compaction.max.size	9223372036854775807	A StoreFile (or a selection of StoreFiles, when using ExploringCompactionPolicy)       larger than this size will be excluded from compaction. The effect of       raising hbase.hstore.compaction.max.size is fewer, larger StoreFiles that do not get       compacted often. If you feel that compaction is happening too often without much benefit, you       can try raising this value. Default: the value of LONG.MAX_VALUE, expressed in bytes.
hbase.hstore.compaction.ratio	1.2F	For minor compaction, this ratio is used to determine whether a given StoreFile       which is larger than hbase.hstore.compaction.min.size is eligible for compaction. Its       effect is to limit compaction of large StoreFiles. The value of hbase.hstore.compaction.ratio       is expressed as a floating-point decimal. A large ratio, such as 10, will produce a single       giant StoreFile. Conversely, a low value, such as .25, will produce behavior similar to the       BigTable compaction algorithm, producing four StoreFiles. A moderate value of between 1.0 and       1.4 is recommended. When tuning this value, you are balancing write costs with read costs.       Raising the value (to something like 1.4) will have more write costs, because you will       compact larger StoreFiles. However, during reads, HBase will need to seek through fewer       StoreFiles to accomplish the read. Consider this approach if you cannot take advantage of       Bloom filters. Otherwise, you can lower this value to something like 1.0 to reduce the       background cost of writes, and use Bloom filters to control the number of StoreFiles touched       during reads. For most cases, the default value is appropriate.
hbase.regionserver.thread.compaction.throttle	2684354560	There are two different thread pools for compactions, one for large compactions and       the other for small compactions. This helps to keep compaction of lean tables (such as       hbase:meta) fast. If a compaction is larger than this threshold, it       goes into the large compaction pool. In most cases, the default value is appropriate. Default:       2 x hbase.hstore.compaction.max x hbase.hregion.memstore.flush.size (which defaults to 128MB).       The value field assumes that the value of hbase.hregion.memstore.flush.size is unchanged from       the default.
hbase.bucketcache.ioengine		Where to store the contents of the bucketcache. One of: offheap,     file, files or mmap. If a file or files, set it to file(s):PATH_TO_FILE.     mmap means the content will be in an mmaped file. Use mmap:PATH_TO_FILE.     See http://hbase.apache.org/book.html#offheap.blockcache for more information.
hbase.bucketcache.bucket.sizes		A comma-separated list of sizes for buckets for the bucketcache.     Can be multiple sizes. List block sizes in order from smallest to largest.     The sizes you use will depend on your data access patterns.     Must be a multiple of 256 else you will run into     'java.io.IOException: Invalid HFile block magic' when you go to read from cache.     If you specify no values here, then you pick up the default bucketsizes set     in code (See BucketAllocator#DEFAULT_BUCKET_SIZES).
hbase.rpc.timeout	60000	This is for the RPC layer to define how long (millisecond) HBase client applications         take for a remote call to time out. It uses pings to check connections         but will eventually throw a TimeoutException.
hbase.client.operation.timeout	1200000	Operation timeout is a top-level restriction (millisecond) that makes sure a       blocking operation in Table will not be blocked more than this. In each operation, if rpc       request fails because of timeout or other reason, it will retry until success or throw       RetriesExhaustedException. But if the total time being blocking reach the operation timeout       before retries exhausted, it will break early and throw SocketTimeoutException.
hbase.cells.scanned.per.heartbeat.check	10000	The number of cells scanned in between heartbeat checks. Heartbeat         checks occur during the processing of scans to determine whether or not the         server should stop scanning in order to send back a heartbeat message to the         client. Heartbeat messages are used to keep the client-server connection alive         during long running scans. Small values mean that the heartbeat checks will         occur more often and thus will provide a tighter bound on the execution time of         the scan. Larger values mean that the heartbeat checks occur less frequently
hbase.rpc.shortoperation.timeout	10000	This is another version of "hbase.rpc.timeout". For those RPC operation         within cluster, we rely on this configuration to set a short timeout limitation         for short operation. For example, short rpc timeout for region server's trying         to report to active master can benefit quicker master failover process.
hbase.superuser		List of users or groups (comma-separated), who are allowed     full privileges, regardless of stored ACLs, across the cluster.     Only used when HBase security is enabled.
hbase.ipc.server.fallback-to-simple-auth-allowed	false	When a server is configured to require secure connections, it will       reject connection attempts from clients using SASL SIMPLE (unsecure) authentication.       This setting allows secure servers to accept SASL SIMPLE connections from clients       when the client requests.  When false (the default), the server will not allow the fallback       to SIMPLE authentication, and will reject the connection.  WARNING: This setting should ONLY       be used as a temporary measure while converting clients over to secure authentication.  It       MUST BE DISABLED for secure operation.
hbase.coprocessor.region.classes		A comma-separated list of Coprocessors that are loaded by     default on all tables. For any override coprocessor method, these classes     will be called in order. After implementing your own Coprocessor, just put     it in HBase's classpath and add the fully qualified class name here.     A coprocessor can also be loaded on demand by setting HTableDescriptor.
hbase.coprocessor.master.classes		A comma-separated list of     org.apache.hadoop.hbase.coprocessor.MasterObserver coprocessors that are     loaded by default on the active HMaster process. For any implemented     coprocessor methods, the listed classes will be called in order. After     implementing your own MasterObserver, just put it in HBase's classpath     and add the fully qualified class name here.
hbase.rootdir.perms	700	FS Permissions for the root data subdirectory in a secure (kerberos) setup.     When master starts, it creates the rootdir with this permissions or sets the permissions     if it does not match.
hbase.wal.dir.perms	700	FS Permissions for the root WAL directory in a secure(kerberos) setup.       When master starts, it creates the WAL dir with this permissions or sets the permissions       if it does not match.
hbase.data.umask	000	File permissions that should be used to write data       files when hbase.data.umask.enable is true
hbase.snapshot.restore.failsafe.name	hbase-failsafe-{snapshot.name}-{restore.timestamp}	Name of the failsafe snapshot taken by the restore operation.       You can use the {snapshot.name}, {table.name} and {restore.timestamp} variables       to create a name based on what you are restoring.
hbase.server.compactchecker.interval.multiplier	1000	The number that determines how often we scan to see if compaction is necessary.         Normally, compactions are done after some events (such as memstore flush), but if         region didn't receive a lot of writes for some time, or due to different compaction         policies, it may be necessary to check it periodically. The interval between checks is         hbase.server.compactchecker.interval.multiplier multiplied by         hbase.server.thread.wakefrequency.
hbase.lease.recovery.timeout	900000	How long we wait on dfs lease recovery in total before giving up.
hbase.lease.recovery.dfs.timeout	64000	How long between dfs recover lease invocations. Should be larger than the sum of         the time it takes for the namenode to issue a block recovery command as part of         datanode; dfs.heartbeat.interval and the time it takes for the primary         datanode, performing block recovery to timeout on a dead datanode; usually         dfs.client.socket-timeout. See the end of HBASE-8389 for more.
hbase.regionserver.checksum.verify	true	If set to true (the default), HBase verifies the checksums for hfile         blocks. HBase writes checksums inline with the data when it writes out         hfiles. HDFS (as of this writing) writes checksums to a separate file         than the data file necessitating extra seeks.  Setting this flag saves         some on i/o.  Checksum verification by HDFS will be internally disabled         on hfile streams when this flag is set.  If the hbase-checksum verification         fails, we will switch back to using HDFS checksums (so do not disable HDFS         checksums!  And besides this feature applies to hfiles only, not to WALs).         If this parameter is set to false, then hbase will not verify any checksums,         instead it will depend on checksum verification being done in the HDFS client.
hbase.hstore.bytes.per.checksum	16384	Number of bytes in a newly created checksum chunk for HBase-level         checksums in hfile blocks.
hbase.hstore.checksum.algorithm	CRC32C	Name of an algorithm that is used to compute checksums. Possible values       are NULL, CRC32, CRC32C.
hbase.client.scanner.max.result.size	2097152	Maximum number of bytes returned when calling a scanner's next method.     Note that when a single row is larger than this limit the row is still returned completely.     The default value is 2MB, which is good for 1ge networks.     With faster and/or high latency networks this value should be increased.
hbase.server.scanner.max.result.size	104857600	Maximum number of bytes returned when calling a scanner's next method.     Note that when a single row is larger than this limit the row is still returned completely.     The default value is 100MB.     This is a safety setting to protect the server from OOM situations.
hbase.status.publisher.class	org.apache.hadoop.hbase.master.ClusterStatusPublisher$MulticastPublisher	Implementation of the status publication with a multicast message.
hbase.status.listener.class	org.apache.hadoop.hbase.client.ClusterStatusListener$MulticastListener	Implementation of the status listener with a multicast message.
hbase.status.multicast.address.ip	226.1.1.3	Multicast address to use for the status publication by multicast.
hbase.status.multicast.address.port	16100	Multicast port to use for the status publication by multicast.
hbase.dynamic.jars.dir	${hbase.rootdir}/lib	The directory from which the custom filter JARs can be loaded       dynamically by the region server without the need to restart. However,       an already loaded filter/co-processor class would not be un-loaded. See       HBASE-1936 for more details.        Does not apply to coprocessors.
hbase.master.loadbalancer.class	org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer	Class used to execute the regions balancing when the period occurs.       See the class comment for more on how it works       http://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.html       It replaces the DefaultLoadBalancer as the default (since renamed       as the SimpleLoadBalancer).
hbase.master.normalizer.class	org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer	Class used to execute the region normalization when the period occurs.       See the class comment for more on how it works       http://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.html
hbase.procedure.master.classes      A comma-separated list of     org.apache.hadoop.hbase.procedure.MasterProcedureManager procedure managers that are     loaded by default on the active HMaster process. A procedure is identified by its signature and     users can use the signature and an instant name to trigger an execution of a globally barriered     procedure. After implementing your own MasterProcedureManager, just put it in HBase's classpath     and add the fully qualified class name here.
hbase.regionserver.storefile.refresh.period	0	The period (in milliseconds) for refreshing the store files for the secondary regions. 0       means this feature is disabled. Secondary regions sees new files (from flushes and       compactions) from primary once the secondary region refreshes the list of files in the       region (there is no notification mechanism). But too frequent refreshes might cause       extra Namenode pressure. If the files cannot be refreshed for longer than HFile TTL       (hbase.master.hfilecleaner.ttl) the requests are rejected. Configuring HFile TTL to a larger       value is also recommended with this setting.
hbase.http.filter.initializers	org.apache.hadoop.hbase.http.lib.StaticUserWebFilter	A comma separated list of class names. Each class in the list must extend       org.apache.hadoop.hbase.http.FilterInitializer. The corresponding Filter will       be initialized. Then, the Filter will be applied to all user facing jsp       and servlet web pages.       The ordering of the list defines the ordering of the filters.       The default StaticUserWebFilter add a user principal as defined by the       hbase.http.staticuser.user property.
hbase.http.max.threads	16	The maximum number of threads that the HTTP Server will create in its       ThreadPool.
hbase.replication.rpc.codec	org.apache.hadoop.hbase.codec.KeyValueCodecWithTags	The codec that is to be used when replication is enabled so that     the tags are also replicated. This is used along with HFileV3 which     supports tags in them.  If tags are not used or if the hfile version used     is HFileV2 then KeyValueCodec can be used as the replication codec. Note that     using KeyValueCodecWithTags for replication when there are no tags causes no harm.
hbase.replication.source.maxthreads	10	The maximum number of threads any replication source will use for         shipping edits to the sinks in parallel. This also limits the number of         chunks each replication batch is broken into. Larger values can improve         the replication throughput between the master and slave clusters. The         default of 10 will rarely need to be changed.
hbase.regionserver.handler.abort.on.error.percent	0.5	The percent of region server RPC threads failed to abort RS.     -1 Disable aborting; 0 Abort if even a single handler has died;     0.x Abort only when this percent of handlers have died;     1 Abort only all of the handers have died.
hbase.mob.file.cache.size	1000	Number of opened file handlers to cache.       A larger value will benefit reads by providing more file handlers per mob       file cache and would reduce frequent file opening and closing.       However, if this is set too high, this could lead to a "too many opened file handlers"       The default value is 1000.
hbase.mob.cache.evict.period	3600	The amount of time in seconds before the mob cache evicts cached mob files.       The default value is 3600 seconds.
hbase.mob.cache.evict.remain.ratio	0.5f	The ratio (between 0.0 and 1.0) of files that remains cached after an eviction       is triggered when the number of cached mob files exceeds the hbase.mob.file.cache.size.       The default value is 0.5f.
hbase.master.mob.ttl.cleaner.period	86400	The period that ExpiredMobFileCleanerChore runs. The unit is second.       The default value is one day. The MOB file name uses only the date part of       the file creation time in it. We use this time for deciding TTL expiry of       the files. So the removal of TTL expired files might be delayed. The max       delay might be 24 hrs.
hbase.mob.compaction.threads.max	1	The max number of threads used in MobCompactor.
hbase.snapshot.master.timeout.millis	300000	Timeout for master for the snapshot procedure execution.
hbase.rpc.rows.warning.threshold	5000	Number of rows in a batch operation above which a warning will be logged.
