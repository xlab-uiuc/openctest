diff --git a/core/src/main/scala/kafka/log/LogConfig.scala b/core/src/main/scala/kafka/log/LogConfig.scala
index 7b008fe26a..3d82e31a9e 100755
--- a/core/src/main/scala/kafka/log/LogConfig.scala
+++ b/core/src/main/scala/kafka/log/LogConfig.scala
@@ -286,6 +286,7 @@ object LogConfig {
                importance: ConfigDef.Importance, doc: String, serverDefaultConfigName: String): LogConfigDef = {
       super.define(name, defType, defaultValue, validator, importance, doc)
       serverDefaultConfigNames.put(name, serverDefaultConfigName)
+      println("[CTEST][SET-PARAM] " + serverDefaultConfigName + getStackTrace)
       this
     }
 
@@ -293,6 +294,7 @@ object LogConfig {
                documentation: String, serverDefaultConfigName: String): LogConfigDef = {
       super.define(name, defType, defaultValue, importance, documentation)
       serverDefaultConfigNames.put(name, serverDefaultConfigName)
+      println("[CTEST][SET-PARAM] " + serverDefaultConfigName + getStackTrace)
       this
     }
 
@@ -300,9 +302,18 @@ object LogConfig {
                serverDefaultConfigName: String): LogConfigDef = {
       super.define(name, defType, importance, documentation)
       serverDefaultConfigNames.put(name, serverDefaultConfigName)
+      println("[CTEST][SET-PARAM] " + serverDefaultConfigName + getStackTrace)
       this
     }
 
+    def getStackTrace: String = {
+      var stacktrace = " "
+      for (element <- Thread.currentThread.getStackTrace) {
+        stacktrace = stacktrace.concat(element.getClassName + "#")
+      }
+      stacktrace
+    }
+
     override def headers = List("Name", "Description", "Type", "Default", "Valid Values", ServerDefaultHeaderName,
       "Importance").asJava
 
diff --git a/core/src/main/scala/kafka/server/KafkaConfig.scala b/core/src/main/scala/kafka/server/KafkaConfig.scala
index 497a904c2c..9bceb18c24 100755
--- a/core/src/main/scala/kafka/server/KafkaConfig.scala
+++ b/core/src/main/scala/kafka/server/KafkaConfig.scala
@@ -27,7 +27,7 @@ import kafka.log.LogConfig
 import kafka.log.LogConfig.MessageFormatVersion
 import kafka.message.{BrokerCompressionCodec, CompressionCodec, ProducerCompressionCodec, ZStdCompressionCodec}
 import kafka.security.authorizer.AuthorizerUtils
-import kafka.server.KafkaConfig.{ControllerListenerNamesProp, ListenerSecurityProtocolMapProp}
+import kafka.server.KafkaConfig.{ControllerListenerNamesProp, ListenerSecurityProtocolMapProp, getStackTrace}
 import kafka.server.KafkaRaftServer.{BrokerRole, ControllerRole, ProcessRole}
 import kafka.utils.CoreUtils.parseCsvList
 import kafka.utils.{CoreUtils, Logging}
@@ -1414,8 +1414,15 @@ object KafkaConfig {
   def fromProps(props: Properties): KafkaConfig =
     fromProps(props, true)
 
-  def fromProps(props: Properties, doLog: Boolean): KafkaConfig =
+  def fromProps(props: Properties, doLog: Boolean): KafkaConfig = {
+    // Print log for CTEST
+    val keys = props.keys
+    while (keys.hasMoreElements) {
+      val key = keys.nextElement.toString
+      println("[CTEST][SET-PARAM] " + key + getStackTrace)
+    }
     new KafkaConfig(props, doLog)
+  }
 
   def fromProps(defaults: Properties, overrides: Properties): KafkaConfig =
     fromProps(defaults, overrides, true)
@@ -1427,6 +1434,14 @@ object KafkaConfig {
     fromProps(props, doLog)
   }
 
+  def getStackTrace: String = {
+    var stacktrace = " "
+    for (element <- Thread.currentThread.getStackTrace) {
+      stacktrace = stacktrace.concat(element.getClassName + "#")
+    }
+    stacktrace
+  }
+
   def apply(props: java.util.Map[_, _], doLog: Boolean = true): KafkaConfig = new KafkaConfig(props, doLog)
 
   private def typeOf(name: String): Option[ConfigDef.Type] = Option(configDef.configKeys.get(name)).map(_.`type`)
@@ -1532,12 +1547,32 @@ class KafkaConfig private(doLog: Boolean, val props: java.util.Map[_, _], dynami
     super.valuesWithPrefixOverride(prefix)
 
   /** ********* Zookeeper Configuration ***********/
-  val zkConnect: String = getString(KafkaConfig.ZkConnectProp)
-  val zkSessionTimeoutMs: Int = getInt(KafkaConfig.ZkSessionTimeoutMsProp)
-  val zkConnectionTimeoutMs: Int =
-    Option(getInt(KafkaConfig.ZkConnectionTimeoutMsProp)).map(_.toInt).getOrElse(getInt(KafkaConfig.ZkSessionTimeoutMsProp))
-  val zkEnableSecureAcls: Boolean = getBoolean(KafkaConfig.ZkEnableSecureAclsProp)
-  val zkMaxInFlightRequests: Int = getInt(KafkaConfig.ZkMaxInFlightRequestsProp)
+  def zkConnect: String = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ZkConnectProp)
+    getString(KafkaConfig.ZkConnectProp)
+  }
+  def zkSessionTimeoutMs: Int = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ZkSessionTimeoutMsProp)
+    getInt(KafkaConfig.ZkSessionTimeoutMsProp)
+  }
+  def zkConnectionTimeoutMs: Int = {
+    val result = Option(getInt(KafkaConfig.ZkConnectionTimeoutMsProp)).map(_.toInt)
+    if (result.isEmpty) {
+      logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ZkSessionTimeoutMsProp)
+      getInt(KafkaConfig.ZkSessionTimeoutMsProp)
+    } else {
+      logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ZkConnectionTimeoutMsProp)
+      result.get
+    }
+  }
+  def zkEnableSecureAcls: Boolean = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ZkEnableSecureAclsProp)
+    getBoolean(KafkaConfig.ZkEnableSecureAclsProp)
+  }
+  def zkMaxInFlightRequests: Int = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ZkMaxInFlightRequestsProp)
+    getInt(KafkaConfig.ZkMaxInFlightRequestsProp)
+  }
 
   private val _remoteLogManagerConfig = new RemoteLogManagerConfig(this)
   def remoteLogManagerConfig = _remoteLogManagerConfig
@@ -1585,18 +1620,62 @@ class KafkaConfig private(doLog: Boolean, val props: java.util.Map[_, _], dynami
     }
   }
 
-  val zkSslClientEnable = zkBooleanConfigOrSystemPropertyWithDefaultValue(KafkaConfig.ZkSslClientEnableProp)
-  val zkClientCnxnSocketClassName = zkOptionalStringConfigOrSystemProperty(KafkaConfig.ZkClientCnxnSocketProp)
-  val zkSslKeyStoreLocation = zkOptionalStringConfigOrSystemProperty(KafkaConfig.ZkSslKeyStoreLocationProp)
-  val zkSslKeyStorePassword = zkPasswordConfigOrSystemProperty(KafkaConfig.ZkSslKeyStorePasswordProp)
-  val zkSslKeyStoreType = zkOptionalStringConfigOrSystemProperty(KafkaConfig.ZkSslKeyStoreTypeProp)
-  val zkSslTrustStoreLocation = zkOptionalStringConfigOrSystemProperty(KafkaConfig.ZkSslTrustStoreLocationProp)
-  val zkSslTrustStorePassword = zkPasswordConfigOrSystemProperty(KafkaConfig.ZkSslTrustStorePasswordProp)
-  val zkSslTrustStoreType = zkOptionalStringConfigOrSystemProperty(KafkaConfig.ZkSslTrustStoreTypeProp)
-  val ZkSslProtocol = zkStringConfigOrSystemPropertyWithDefaultValue(KafkaConfig.ZkSslProtocolProp)
-  val ZkSslEnabledProtocols = zkListConfigOrSystemProperty(KafkaConfig.ZkSslEnabledProtocolsProp)
-  val ZkSslCipherSuites = zkListConfigOrSystemProperty(KafkaConfig.ZkSslCipherSuitesProp)
+  def zkSslClientEnable = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ZkSslClientEnableProp)
+    zkBooleanConfigOrSystemPropertyWithDefaultValue(KafkaConfig.ZkSslClientEnableProp)
+  }
+
+  def zkClientCnxnSocketClassName = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ZkClientCnxnSocketProp)
+    zkOptionalStringConfigOrSystemProperty(KafkaConfig.ZkClientCnxnSocketProp)
+  }
+
+  def zkSslKeyStoreLocation = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ZkSslKeyStoreLocationProp)
+    zkOptionalStringConfigOrSystemProperty(KafkaConfig.ZkSslKeyStoreLocationProp)
+  }
+
+  def zkSslKeyStorePassword = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ZkSslKeyStorePasswordProp)
+    zkPasswordConfigOrSystemProperty(KafkaConfig.ZkSslKeyStorePasswordProp)
+  }
+
+  def zkSslKeyStoreType = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ZkSslKeyStoreTypeProp)
+    zkOptionalStringConfigOrSystemProperty(KafkaConfig.ZkSslKeyStoreTypeProp)
+  }
+
+  def zkSslTrustStoreLocation = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ZkSslTrustStoreLocationProp)
+    zkOptionalStringConfigOrSystemProperty(KafkaConfig.ZkSslTrustStoreLocationProp)
+  }
+
+  def zkSslTrustStorePassword = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ZkSslTrustStorePasswordProp)
+    zkPasswordConfigOrSystemProperty(KafkaConfig.ZkSslTrustStorePasswordProp)
+  }
+
+  def zkSslTrustStoreType = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ZkSslTrustStoreTypeProp)
+    zkOptionalStringConfigOrSystemProperty(KafkaConfig.ZkSslTrustStoreTypeProp)
+  }
+
+  def ZkSslProtocol = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ZkSslProtocolProp)
+    zkStringConfigOrSystemPropertyWithDefaultValue(KafkaConfig.ZkSslProtocolProp)
+  }
+
+  def ZkSslEnabledProtocols = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ZkSslEnabledProtocolsProp)
+    zkListConfigOrSystemProperty(KafkaConfig.ZkSslEnabledProtocolsProp)
+  }
+
+  def ZkSslCipherSuites = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ZkSslCipherSuitesProp)
+    zkListConfigOrSystemProperty(KafkaConfig.ZkSslCipherSuitesProp)
+  }
   val ZkSslEndpointIdentificationAlgorithm = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ZkSslEndpointIdentificationAlgorithmProp)
     // Use the system property if it exists and the Kafka config value was defaulted rather than actually provided
     // Need to translate any system property value from true/false to HTTPS/<blank>
     val kafkaProp = KafkaConfig.ZkSslEndpointIdentificationAlgorithmProp
@@ -1611,21 +1690,55 @@ class KafkaConfig private(doLog: Boolean, val props: java.util.Map[_, _], dynami
       }
     }
   }
-  val ZkSslCrlEnable = zkBooleanConfigOrSystemPropertyWithDefaultValue(KafkaConfig.ZkSslCrlEnableProp)
-  val ZkSslOcspEnable = zkBooleanConfigOrSystemPropertyWithDefaultValue(KafkaConfig.ZkSslOcspEnableProp)
+  def ZkSslCrlEnable = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ZkSslCrlEnableProp)
+    zkBooleanConfigOrSystemPropertyWithDefaultValue(KafkaConfig.ZkSslCrlEnableProp)
+  }
+  def ZkSslOcspEnable = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ZkSslOcspEnableProp)
+    zkBooleanConfigOrSystemPropertyWithDefaultValue(KafkaConfig.ZkSslOcspEnableProp)
+  }
   /** ********* General Configuration ***********/
-  val brokerIdGenerationEnable: Boolean = getBoolean(KafkaConfig.BrokerIdGenerationEnableProp)
-  val maxReservedBrokerId: Int = getInt(KafkaConfig.MaxReservedBrokerIdProp)
-  var brokerId: Int = getInt(KafkaConfig.BrokerIdProp)
-  val nodeId: Int = getInt(KafkaConfig.NodeIdProp)
-  val initialRegistrationTimeoutMs: Int = getInt(KafkaConfig.InitialBrokerRegistrationTimeoutMsProp)
-  val brokerHeartbeatIntervalMs: Int = getInt(KafkaConfig.BrokerHeartbeatIntervalMsProp)
-  val brokerSessionTimeoutMs: Int = getInt(KafkaConfig.BrokerSessionTimeoutMsProp)
+  def brokerIdGenerationEnable: Boolean = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.BrokerIdGenerationEnableProp)
+    getBoolean(KafkaConfig.BrokerIdGenerationEnableProp)
+  }
+  def maxReservedBrokerId: Int = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.MaxReservedBrokerIdProp)
+    getInt(KafkaConfig.MaxReservedBrokerIdProp)
+  }
+
+  var originalBrokerId: Int = getInt(KafkaConfig.BrokerIdProp)
+  def brokerId: Int = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.BrokerIdProp)
+    originalBrokerId
+  }
+  def setBrokerId(newBrokerId: Int) = {
+    logger.info("[CTEST][SET-PARAM] " + KafkaConfig.BrokerIdProp + getStackTrace)
+    originalBrokerId = newBrokerId
+  }
+  def nodeId: Int = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.NodeIdProp)
+    getInt(KafkaConfig.NodeIdProp)
+  }
+  def initialRegistrationTimeoutMs: Int = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.InitialBrokerRegistrationTimeoutMsProp)
+    getInt(KafkaConfig.InitialBrokerRegistrationTimeoutMsProp)
+  }
+  def brokerHeartbeatIntervalMs: Int = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.BrokerHeartbeatIntervalMsProp)
+    getInt(KafkaConfig.BrokerHeartbeatIntervalMsProp)
+  }
+  def brokerSessionTimeoutMs: Int = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.BrokerSessionTimeoutMsProp)
+    getInt(KafkaConfig.BrokerSessionTimeoutMsProp)
+  }
 
   def requiresZookeeper: Boolean = processRoles.isEmpty
   def usesSelfManagedQuorum: Boolean = processRoles.nonEmpty
 
   private def parseProcessRoles(): Set[ProcessRole] = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ProcessRolesProp)
     val roles = getList(KafkaConfig.ProcessRolesProp).asScala.map {
       case "broker" => BrokerRole
       case "controller" => ControllerRole
@@ -1653,35 +1766,84 @@ class KafkaConfig private(doLog: Boolean, val props: java.util.Map[_, _], dynami
     }
   }
 
-  def metadataLogSegmentBytes = getInt(KafkaConfig.MetadataLogSegmentBytesProp)
-  def metadataLogSegmentMillis = getLong(KafkaConfig.MetadataLogSegmentMillisProp)
-  def metadataRetentionBytes = getLong(KafkaConfig.MetadataMaxRetentionBytesProp)
-  def metadataRetentionMillis = getLong(KafkaConfig.MetadataMaxRetentionMillisProp)
+  def metadataLogSegmentBytes = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.MetadataLogSegmentBytesProp)
+    getInt(KafkaConfig.MetadataLogSegmentBytesProp)
+  }
+  def metadataLogSegmentMillis = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.MetadataLogSegmentMillisProp)
+    getLong(KafkaConfig.MetadataLogSegmentMillisProp)
+  }
+  def metadataRetentionBytes = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.MetadataMaxRetentionBytesProp)
+    getLong(KafkaConfig.MetadataMaxRetentionBytesProp)
+  }
+  def metadataRetentionMillis = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.MetadataMaxRetentionMillisProp)
+    getLong(KafkaConfig.MetadataMaxRetentionMillisProp)
+  }
 
-  def numNetworkThreads = getInt(KafkaConfig.NumNetworkThreadsProp)
-  def backgroundThreads = getInt(KafkaConfig.BackgroundThreadsProp)
-  val queuedMaxRequests = getInt(KafkaConfig.QueuedMaxRequestsProp)
-  val queuedMaxBytes = getLong(KafkaConfig.QueuedMaxBytesProp)
-  def numIoThreads = getInt(KafkaConfig.NumIoThreadsProp)
-  def messageMaxBytes = getInt(KafkaConfig.MessageMaxBytesProp)
-  val requestTimeoutMs = getInt(KafkaConfig.RequestTimeoutMsProp)
-  val connectionSetupTimeoutMs = getLong(KafkaConfig.ConnectionSetupTimeoutMsProp)
-  val connectionSetupTimeoutMaxMs = getLong(KafkaConfig.ConnectionSetupTimeoutMaxMsProp)
+  def numNetworkThreads = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.NumNetworkThreadsProp)
+    getInt(KafkaConfig.NumNetworkThreadsProp)
+  }
+  def backgroundThreads = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.BackgroundThreadsProp)
+    getInt(KafkaConfig.BackgroundThreadsProp)
+  }
+  def queuedMaxRequests = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.QueuedMaxRequestsProp)
+    getInt(KafkaConfig.QueuedMaxRequestsProp)
+  }
+  def queuedMaxBytes = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.QueuedMaxBytesProp)
+    getLong(KafkaConfig.QueuedMaxBytesProp)
+  }
+  def numIoThreads = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.NumIoThreadsProp)
+    getInt(KafkaConfig.NumIoThreadsProp)
+  }
+  def messageMaxBytes = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.MessageMaxBytesProp)
+    getInt(KafkaConfig.MessageMaxBytesProp)
+  }
+  def requestTimeoutMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.RequestTimeoutMsProp)
+    getInt(KafkaConfig.RequestTimeoutMsProp)
+  }
+  def connectionSetupTimeoutMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ConnectionSetupTimeoutMsProp)
+    getLong(KafkaConfig.ConnectionSetupTimeoutMsProp)
+  }
+  def connectionSetupTimeoutMaxMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ConnectionSetupTimeoutMaxMsProp)
+    getLong(KafkaConfig.ConnectionSetupTimeoutMaxMsProp)
+  }
 
   def getNumReplicaAlterLogDirsThreads: Int = {
-    val numThreads: Integer = Option(getInt(KafkaConfig.NumReplicaAlterLogDirsThreadsProp)).getOrElse(logDirs.size)
-    numThreads
+    val numThreads = Option(getInt(KafkaConfig.NumReplicaAlterLogDirsThreadsProp)).map(_.toInt)
+    if (numThreads.isEmpty) {
+      logDirs.size
+    } else {
+      logger.info("[CTEST][GET-PARAM] " + KafkaConfig.NumReplicaAlterLogDirsThreadsProp)
+      numThreads.get
+    }
   }
 
   /************* Metadata Configuration ***********/
-  val metadataSnapshotMaxNewRecordBytes = getLong(KafkaConfig.MetadataSnapshotMaxNewRecordBytesProp)
+  def metadataSnapshotMaxNewRecordBytes = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.MetadataSnapshotMaxNewRecordBytesProp)
+    getLong(KafkaConfig.MetadataSnapshotMaxNewRecordBytesProp)
+  }
   val metadataMaxIdleIntervalNs: Option[Long] = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.MetadataMaxIdleIntervalMsProp)
     val value = TimeUnit.NANOSECONDS.convert(getInt(KafkaConfig.MetadataMaxIdleIntervalMsProp).toLong, TimeUnit.MILLISECONDS)
     if (value > 0) Some(value) else None
   }
 
   /************* Authorizer Configuration ***********/
   def createNewAuthorizer(): Option[Authorizer] = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.AuthorizerClassNameProp)
     val className = getString(KafkaConfig.AuthorizerClassNameProp)
     if (className == null || className.isEmpty)
       None
@@ -1691,6 +1853,7 @@ class KafkaConfig private(doLog: Boolean, val props: java.util.Map[_, _], dynami
   }
 
   val earlyStartListeners: Set[ListenerName] = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.EarlyStartListenersProp)
     val listenersSet = listeners.map(_.listenerName).toSet
     val controllerListenersSet = controllerListeners.map(_.listenerName).toSet
     Option(getString(KafkaConfig.EarlyStartListenersProp)) match {
@@ -1708,98 +1871,329 @@ class KafkaConfig private(doLog: Boolean, val props: java.util.Map[_, _], dynami
   }
 
   /** ********* Socket Server Configuration ***********/
-  val socketSendBufferBytes = getInt(KafkaConfig.SocketSendBufferBytesProp)
-  val socketReceiveBufferBytes = getInt(KafkaConfig.SocketReceiveBufferBytesProp)
-  val socketRequestMaxBytes = getInt(KafkaConfig.SocketRequestMaxBytesProp)
-  val socketListenBacklogSize = getInt(KafkaConfig.SocketListenBacklogSizeProp)
-  val maxConnectionsPerIp = getInt(KafkaConfig.MaxConnectionsPerIpProp)
-  val maxConnectionsPerIpOverrides: Map[String, Int] =
+  def socketSendBufferBytes = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.SocketSendBufferBytesProp)
+    getInt(KafkaConfig.SocketSendBufferBytesProp)
+  }
+  def socketReceiveBufferBytes = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.SocketReceiveBufferBytesProp)
+    getInt(KafkaConfig.SocketReceiveBufferBytesProp)
+  }
+  def socketRequestMaxBytes = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.SocketRequestMaxBytesProp)
+    getInt(KafkaConfig.SocketRequestMaxBytesProp)
+  }
+  def socketListenBacklogSize = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.SocketListenBacklogSizeProp)
+    getInt(KafkaConfig.SocketListenBacklogSizeProp)
+  }
+  def maxConnectionsPerIp = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.MaxConnectionsPerIpProp)
+    getInt(KafkaConfig.MaxConnectionsPerIpProp)
+  }
+  def maxConnectionsPerIpOverrides: Map[String, Int] = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.MaxConnectionsPerIpOverridesProp)
     getMap(KafkaConfig.MaxConnectionsPerIpOverridesProp, getString(KafkaConfig.MaxConnectionsPerIpOverridesProp)).map { case (k, v) => (k, v.toInt)}
-  def maxConnections = getInt(KafkaConfig.MaxConnectionsProp)
-  def maxConnectionCreationRate = getInt(KafkaConfig.MaxConnectionCreationRateProp)
-  val connectionsMaxIdleMs = getLong(KafkaConfig.ConnectionsMaxIdleMsProp)
-  val failedAuthenticationDelayMs = getInt(KafkaConfig.FailedAuthenticationDelayMsProp)
+  }
+
+  def maxConnections = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.MaxConnectionsProp)
+    getInt(KafkaConfig.MaxConnectionsProp)
+  }
+  def maxConnectionCreationRate = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.MaxConnectionCreationRateProp)
+    getInt(KafkaConfig.MaxConnectionCreationRateProp)
+  }
+  def connectionsMaxIdleMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ConnectionsMaxIdleMsProp)
+    getLong(KafkaConfig.ConnectionsMaxIdleMsProp)
+  }
+  def failedAuthenticationDelayMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.FailedAuthenticationDelayMsProp)
+    getInt(KafkaConfig.FailedAuthenticationDelayMsProp)
+  }
 
   /***************** rack configuration **************/
-  val rack = Option(getString(KafkaConfig.RackProp))
-  val replicaSelectorClassName = Option(getString(KafkaConfig.ReplicaSelectorClassProp))
+  def rack = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.RackProp)
+    Option(getString(KafkaConfig.RackProp))
+  }
+  def replicaSelectorClassName = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ReplicaSelectorClassProp)
+    Option(getString(KafkaConfig.ReplicaSelectorClassProp))
+  }
 
   /** ********* Log Configuration ***********/
-  val autoCreateTopicsEnable = getBoolean(KafkaConfig.AutoCreateTopicsEnableProp)
-  val numPartitions = getInt(KafkaConfig.NumPartitionsProp)
-  val logDirs = CoreUtils.parseCsvList(Option(getString(KafkaConfig.LogDirsProp)).getOrElse(getString(KafkaConfig.LogDirProp)))
-  def logSegmentBytes = getInt(KafkaConfig.LogSegmentBytesProp)
-  def logFlushIntervalMessages = getLong(KafkaConfig.LogFlushIntervalMessagesProp)
-  val logCleanerThreads = getInt(KafkaConfig.LogCleanerThreadsProp)
-  def numRecoveryThreadsPerDataDir = getInt(KafkaConfig.NumRecoveryThreadsPerDataDirProp)
-  val logFlushSchedulerIntervalMs = getLong(KafkaConfig.LogFlushSchedulerIntervalMsProp)
-  val logFlushOffsetCheckpointIntervalMs = getInt(KafkaConfig.LogFlushOffsetCheckpointIntervalMsProp).toLong
-  val logFlushStartOffsetCheckpointIntervalMs = getInt(KafkaConfig.LogFlushStartOffsetCheckpointIntervalMsProp).toLong
-  val logCleanupIntervalMs = getLong(KafkaConfig.LogCleanupIntervalMsProp)
-  def logCleanupPolicy = getList(KafkaConfig.LogCleanupPolicyProp)
-  val offsetsRetentionMinutes = getInt(KafkaConfig.OffsetsRetentionMinutesProp)
-  val offsetsRetentionCheckIntervalMs = getLong(KafkaConfig.OffsetsRetentionCheckIntervalMsProp)
-  def logRetentionBytes = getLong(KafkaConfig.LogRetentionBytesProp)
-  val logCleanerDedupeBufferSize = getLong(KafkaConfig.LogCleanerDedupeBufferSizeProp)
-  val logCleanerDedupeBufferLoadFactor = getDouble(KafkaConfig.LogCleanerDedupeBufferLoadFactorProp)
-  val logCleanerIoBufferSize = getInt(KafkaConfig.LogCleanerIoBufferSizeProp)
-  val logCleanerIoMaxBytesPerSecond = getDouble(KafkaConfig.LogCleanerIoMaxBytesPerSecondProp)
-  def logCleanerDeleteRetentionMs = getLong(KafkaConfig.LogCleanerDeleteRetentionMsProp)
-  def logCleanerMinCompactionLagMs = getLong(KafkaConfig.LogCleanerMinCompactionLagMsProp)
-  def logCleanerMaxCompactionLagMs = getLong(KafkaConfig.LogCleanerMaxCompactionLagMsProp)
-  val logCleanerBackoffMs = getLong(KafkaConfig.LogCleanerBackoffMsProp)
-  def logCleanerMinCleanRatio = getDouble(KafkaConfig.LogCleanerMinCleanRatioProp)
-  val logCleanerEnable = getBoolean(KafkaConfig.LogCleanerEnableProp)
-  def logIndexSizeMaxBytes = getInt(KafkaConfig.LogIndexSizeMaxBytesProp)
-  def logIndexIntervalBytes = getInt(KafkaConfig.LogIndexIntervalBytesProp)
-  def logDeleteDelayMs = getLong(KafkaConfig.LogDeleteDelayMsProp)
-  def logRollTimeMillis: java.lang.Long = Option(getLong(KafkaConfig.LogRollTimeMillisProp)).getOrElse(60 * 60 * 1000L * getInt(KafkaConfig.LogRollTimeHoursProp))
-  def logRollTimeJitterMillis: java.lang.Long = Option(getLong(KafkaConfig.LogRollTimeJitterMillisProp)).getOrElse(60 * 60 * 1000L * getInt(KafkaConfig.LogRollTimeJitterHoursProp))
-  def logFlushIntervalMs: java.lang.Long = Option(getLong(KafkaConfig.LogFlushIntervalMsProp)).getOrElse(getLong(KafkaConfig.LogFlushSchedulerIntervalMsProp))
-  def minInSyncReplicas = getInt(KafkaConfig.MinInSyncReplicasProp)
-  def logPreAllocateEnable: java.lang.Boolean = getBoolean(KafkaConfig.LogPreAllocateProp)
+  def autoCreateTopicsEnable = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.AutoCreateTopicsEnableProp)
+    getBoolean(KafkaConfig.AutoCreateTopicsEnableProp)
+  }
+  def numPartitions = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.NumPartitionsProp)
+    getInt(KafkaConfig.NumPartitionsProp)
+  }
+  def logDirs = {
+    val result = Option(getString(KafkaConfig.LogDirsProp))
+    if (result.isEmpty) {
+      logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogDirProp)
+      CoreUtils.parseCsvList(getString(KafkaConfig.LogDirProp))
+    } else {
+      logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogDirsProp)
+      CoreUtils.parseCsvList(result.get)
+    }
+  }
+  def logSegmentBytes = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogSegmentBytesProp)
+    getInt(KafkaConfig.LogSegmentBytesProp)
+  }
+  def logFlushIntervalMessages = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogFlushIntervalMessagesProp)
+    getLong(KafkaConfig.LogFlushIntervalMessagesProp)
+  }
+  def logCleanerThreads = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogCleanerThreadsProp)
+    getInt(KafkaConfig.LogCleanerThreadsProp)
+  }
+  def numRecoveryThreadsPerDataDir = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.NumRecoveryThreadsPerDataDirProp)
+    getInt(KafkaConfig.NumRecoveryThreadsPerDataDirProp)
+  }
+  def logFlushSchedulerIntervalMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogFlushSchedulerIntervalMsProp)
+    getLong(KafkaConfig.LogFlushSchedulerIntervalMsProp)
+  }
+  def logFlushOffsetCheckpointIntervalMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogFlushOffsetCheckpointIntervalMsProp)
+    getInt(KafkaConfig.LogFlushOffsetCheckpointIntervalMsProp).toLong
+  }
+  def logFlushStartOffsetCheckpointIntervalMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogFlushStartOffsetCheckpointIntervalMsProp)
+    getInt(KafkaConfig.LogFlushStartOffsetCheckpointIntervalMsProp).toLong
+  }
+  def logCleanupIntervalMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogCleanupIntervalMsProp)
+    getLong(KafkaConfig.LogCleanupIntervalMsProp)
+  }
+  def logCleanupPolicy = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogCleanupPolicyProp)
+    getList(KafkaConfig.LogCleanupPolicyProp)
+  }
+  def offsetsRetentionMinutes = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.OffsetsRetentionMinutesProp)
+    getInt(KafkaConfig.OffsetsRetentionMinutesProp)
+  }
+  def offsetsRetentionCheckIntervalMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.OffsetsRetentionCheckIntervalMsProp)
+    getLong(KafkaConfig.OffsetsRetentionCheckIntervalMsProp)
+  }
+  def logRetentionBytes = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogRetentionBytesProp)
+    getLong(KafkaConfig.LogRetentionBytesProp)
+  }
+  def logCleanerDedupeBufferSize = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogCleanerDedupeBufferSizeProp)
+    getLong(KafkaConfig.LogCleanerDedupeBufferSizeProp)
+  }
+  def logCleanerDedupeBufferLoadFactor = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogCleanerDedupeBufferLoadFactorProp)
+    getDouble(KafkaConfig.LogCleanerDedupeBufferLoadFactorProp)
+  }
+  def logCleanerIoBufferSize = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogCleanerIoBufferSizeProp)
+    getInt(KafkaConfig.LogCleanerIoBufferSizeProp)
+  }
+  def logCleanerIoMaxBytesPerSecond = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogCleanerIoMaxBytesPerSecondProp)
+    getDouble(KafkaConfig.LogCleanerIoMaxBytesPerSecondProp)
+  }
+  def logCleanerDeleteRetentionMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogCleanerDeleteRetentionMsProp)
+    getLong(KafkaConfig.LogCleanerDeleteRetentionMsProp)
+  }
+  def logCleanerMinCompactionLagMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogCleanerMinCompactionLagMsProp)
+    getLong(KafkaConfig.LogCleanerMinCompactionLagMsProp)
+  }
+  def logCleanerMaxCompactionLagMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogCleanerMaxCompactionLagMsProp)
+    getLong(KafkaConfig.LogCleanerMaxCompactionLagMsProp)
+  }
+  def logCleanerBackoffMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogCleanerBackoffMsProp)
+    getLong(KafkaConfig.LogCleanerBackoffMsProp)
+  }
+  def logCleanerMinCleanRatio = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogCleanerMinCleanRatioProp)
+    getDouble(KafkaConfig.LogCleanerMinCleanRatioProp)
+  }
+  def logCleanerEnable = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogCleanerEnableProp)
+    getBoolean(KafkaConfig.LogCleanerEnableProp)
+  }
+  def logIndexSizeMaxBytes = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogIndexSizeMaxBytesProp)
+    getInt(KafkaConfig.LogIndexSizeMaxBytesProp)
+  }
+  def logIndexIntervalBytes = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogIndexIntervalBytesProp)
+    getInt(KafkaConfig.LogIndexIntervalBytesProp)
+  }
+  def logDeleteDelayMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogDeleteDelayMsProp)
+    getLong(KafkaConfig.LogDeleteDelayMsProp)
+  }
+  def logRollTimeMillis: java.lang.Long = {
+    val result = Option(getLong(KafkaConfig.LogRollTimeMillisProp))
+    if (result.isEmpty) {
+      logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogRollTimeHoursProp)
+      60 * 60 * 1000L * getInt(KafkaConfig.LogRollTimeHoursProp)
+    } else {
+      logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogRollTimeMillisProp)
+      result.get
+    }
+  }
+  def logRollTimeJitterMillis: java.lang.Long = {
+    val result =  Option(getLong(KafkaConfig.LogRollTimeJitterMillisProp))
+    if (result.isEmpty) {
+      logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogRollTimeJitterHoursProp)
+      60 * 60 * 1000L * getInt(KafkaConfig.LogRollTimeJitterHoursProp)
+    } else {
+      logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogRollTimeJitterMillisProp)
+      result.get
+    }
+  }
+  def logFlushIntervalMs: java.lang.Long = {
+    val result = Option(getLong(KafkaConfig.LogFlushIntervalMsProp))
+    if (result.isEmpty) {
+      logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogFlushSchedulerIntervalMsProp)
+      getLong(KafkaConfig.LogFlushSchedulerIntervalMsProp)
+    } else {
+      logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogFlushIntervalMsProp)
+      result.get
+    }
+  }
+  def minInSyncReplicas = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.MinInSyncReplicasProp)
+    getInt(KafkaConfig.MinInSyncReplicasProp)
+  }
+  def logPreAllocateEnable: java.lang.Boolean = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogPreAllocateProp)
+    getBoolean(KafkaConfig.LogPreAllocateProp)
+  }
 
   // We keep the user-provided String as `MetadataVersion.fromVersionString` can choose a slightly different version (eg if `0.10.0`
   // is passed, `0.10.0-IV0` may be picked)
   @nowarn("cat=deprecation")
-  private val logMessageFormatVersionString = getString(KafkaConfig.LogMessageFormatVersionProp)
+  private def logMessageFormatVersionString = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogMessageFormatVersionProp)
+    getString(KafkaConfig.LogMessageFormatVersionProp)
+  }
 
   /* See `TopicConfig.MESSAGE_FORMAT_VERSION_CONFIG` for details */
   @deprecated("3.0")
   lazy val logMessageFormatVersion =
-    if (LogConfig.shouldIgnoreMessageFormatVersion(interBrokerProtocolVersion))
-      MetadataVersion.fromVersionString(Defaults.LogMessageFormatVersion)
-    else MetadataVersion.fromVersionString(logMessageFormatVersionString)
+  if (LogConfig.shouldIgnoreMessageFormatVersion(interBrokerProtocolVersion))
+    MetadataVersion.fromVersionString(Defaults.LogMessageFormatVersion)
+  else MetadataVersion.fromVersionString(logMessageFormatVersionString)
 
-  def logMessageTimestampType = TimestampType.forName(getString(KafkaConfig.LogMessageTimestampTypeProp))
-  def logMessageTimestampDifferenceMaxMs: Long = getLong(KafkaConfig.LogMessageTimestampDifferenceMaxMsProp)
-  def logMessageDownConversionEnable: Boolean = getBoolean(KafkaConfig.LogMessageDownConversionEnableProp)
+  def logMessageTimestampType = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogMessageTimestampTypeProp)
+    TimestampType.forName(getString(KafkaConfig.LogMessageTimestampTypeProp))
+  }
+  def logMessageTimestampDifferenceMaxMs: Long = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogMessageTimestampDifferenceMaxMsProp)
+    getLong(KafkaConfig.LogMessageTimestampDifferenceMaxMsProp)
+  }
+  def logMessageDownConversionEnable: Boolean = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogMessageDownConversionEnableProp)
+    getBoolean(KafkaConfig.LogMessageDownConversionEnableProp)
+  }
 
   /** ********* Replication configuration ***********/
-  val controllerSocketTimeoutMs: Int = getInt(KafkaConfig.ControllerSocketTimeoutMsProp)
-  val defaultReplicationFactor: Int = getInt(KafkaConfig.DefaultReplicationFactorProp)
-  val replicaLagTimeMaxMs = getLong(KafkaConfig.ReplicaLagTimeMaxMsProp)
-  val replicaSocketTimeoutMs = getInt(KafkaConfig.ReplicaSocketTimeoutMsProp)
-  val replicaSocketReceiveBufferBytes = getInt(KafkaConfig.ReplicaSocketReceiveBufferBytesProp)
-  val replicaFetchMaxBytes = getInt(KafkaConfig.ReplicaFetchMaxBytesProp)
-  val replicaFetchWaitMaxMs = getInt(KafkaConfig.ReplicaFetchWaitMaxMsProp)
-  val replicaFetchMinBytes = getInt(KafkaConfig.ReplicaFetchMinBytesProp)
-  val replicaFetchResponseMaxBytes = getInt(KafkaConfig.ReplicaFetchResponseMaxBytesProp)
-  val replicaFetchBackoffMs = getInt(KafkaConfig.ReplicaFetchBackoffMsProp)
-  def numReplicaFetchers = getInt(KafkaConfig.NumReplicaFetchersProp)
-  val replicaHighWatermarkCheckpointIntervalMs = getLong(KafkaConfig.ReplicaHighWatermarkCheckpointIntervalMsProp)
-  val fetchPurgatoryPurgeIntervalRequests = getInt(KafkaConfig.FetchPurgatoryPurgeIntervalRequestsProp)
-  val producerPurgatoryPurgeIntervalRequests = getInt(KafkaConfig.ProducerPurgatoryPurgeIntervalRequestsProp)
-  val deleteRecordsPurgatoryPurgeIntervalRequests = getInt(KafkaConfig.DeleteRecordsPurgatoryPurgeIntervalRequestsProp)
-  val autoLeaderRebalanceEnable = getBoolean(KafkaConfig.AutoLeaderRebalanceEnableProp)
-  val leaderImbalancePerBrokerPercentage = getInt(KafkaConfig.LeaderImbalancePerBrokerPercentageProp)
-  val leaderImbalanceCheckIntervalSeconds: Long = getLong(KafkaConfig.LeaderImbalanceCheckIntervalSecondsProp)
-  def uncleanLeaderElectionEnable: java.lang.Boolean = getBoolean(KafkaConfig.UncleanLeaderElectionEnableProp)
+  def controllerSocketTimeoutMs: Int = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ControllerSocketTimeoutMsProp)
+    getInt(KafkaConfig.ControllerSocketTimeoutMsProp)
+  }
+  def defaultReplicationFactor: Int = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.DefaultReplicationFactorProp)
+    getInt(KafkaConfig.DefaultReplicationFactorProp)
+  }
+  def replicaLagTimeMaxMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ReplicaLagTimeMaxMsProp)
+    getLong(KafkaConfig.ReplicaLagTimeMaxMsProp)
+  }
+  def replicaSocketTimeoutMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ReplicaSocketTimeoutMsProp)
+    getInt(KafkaConfig.ReplicaSocketTimeoutMsProp)
+  }
+  def replicaSocketReceiveBufferBytes = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ReplicaSocketReceiveBufferBytesProp)
+    getInt(KafkaConfig.ReplicaSocketReceiveBufferBytesProp)
+  }
+  def replicaFetchMaxBytes = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ReplicaFetchMaxBytesProp)
+    getInt(KafkaConfig.ReplicaFetchMaxBytesProp)
+  }
+  def replicaFetchWaitMaxMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ReplicaFetchWaitMaxMsProp)
+    getInt(KafkaConfig.ReplicaFetchWaitMaxMsProp)
+  }
+  def replicaFetchMinBytes = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ReplicaFetchMinBytesProp)
+    getInt(KafkaConfig.ReplicaFetchMinBytesProp)
+  }
+  def replicaFetchResponseMaxBytes = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ReplicaFetchResponseMaxBytesProp)
+    getInt(KafkaConfig.ReplicaFetchResponseMaxBytesProp)
+  }
+  def replicaFetchBackoffMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ReplicaFetchBackoffMsProp)
+    getInt(KafkaConfig.ReplicaFetchBackoffMsProp)
+  }
+  def numReplicaFetchers = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.NumReplicaFetchersProp)
+    getInt(KafkaConfig.NumReplicaFetchersProp)
+  }
+  def replicaHighWatermarkCheckpointIntervalMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ReplicaHighWatermarkCheckpointIntervalMsProp)
+    getLong(KafkaConfig.ReplicaHighWatermarkCheckpointIntervalMsProp)
+  }
+  def fetchPurgatoryPurgeIntervalRequests = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.FetchPurgatoryPurgeIntervalRequestsProp)
+    getInt(KafkaConfig.FetchPurgatoryPurgeIntervalRequestsProp)
+  }
+  def producerPurgatoryPurgeIntervalRequests = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ProducerPurgatoryPurgeIntervalRequestsProp)
+    getInt(KafkaConfig.ProducerPurgatoryPurgeIntervalRequestsProp)
+  }
+  def deleteRecordsPurgatoryPurgeIntervalRequests = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.DeleteRecordsPurgatoryPurgeIntervalRequestsProp)
+    getInt(KafkaConfig.DeleteRecordsPurgatoryPurgeIntervalRequestsProp)
+  }
+  def autoLeaderRebalanceEnable = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.AutoLeaderRebalanceEnableProp)
+    getBoolean(KafkaConfig.AutoLeaderRebalanceEnableProp)
+  }
+  def leaderImbalancePerBrokerPercentage = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LeaderImbalancePerBrokerPercentageProp)
+    getInt(KafkaConfig.LeaderImbalancePerBrokerPercentageProp)
+  }
+  def leaderImbalanceCheckIntervalSeconds: Long = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LeaderImbalanceCheckIntervalSecondsProp)
+    getLong(KafkaConfig.LeaderImbalanceCheckIntervalSecondsProp)
+  }
+  def uncleanLeaderElectionEnable: java.lang.Boolean = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.UncleanLeaderElectionEnableProp)
+    getBoolean(KafkaConfig.UncleanLeaderElectionEnableProp)
+  }
 
   // We keep the user-provided String as `MetadataVersion.fromVersionString` can choose a slightly different version (eg if `0.10.0`
   // is passed, `0.10.0-IV0` may be picked)
-  val interBrokerProtocolVersionString = getString(KafkaConfig.InterBrokerProtocolVersionProp)
-  val interBrokerProtocolVersion = if (processRoles.isEmpty) {
+  def interBrokerProtocolVersionString = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.InterBrokerProtocolVersionProp)
+    getString(KafkaConfig.InterBrokerProtocolVersionProp)
+  }
+  def interBrokerProtocolVersion = if (processRoles.isEmpty) {
     MetadataVersion.fromVersionString(interBrokerProtocolVersionString)
   } else {
     if (originals.containsKey(KafkaConfig.InterBrokerProtocolVersionProp)) {
@@ -1820,51 +2214,132 @@ class KafkaConfig private(doLog: Boolean, val props: java.util.Map[_, _], dynami
   }
 
   /** ********* Controlled shutdown configuration ***********/
-  val controlledShutdownMaxRetries = getInt(KafkaConfig.ControlledShutdownMaxRetriesProp)
-  val controlledShutdownRetryBackoffMs = getLong(KafkaConfig.ControlledShutdownRetryBackoffMsProp)
-  val controlledShutdownEnable = getBoolean(KafkaConfig.ControlledShutdownEnableProp)
+  def controlledShutdownMaxRetries = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ControlledShutdownMaxRetriesProp)
+    getInt(KafkaConfig.ControlledShutdownMaxRetriesProp)
+  }
+  def controlledShutdownRetryBackoffMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ControlledShutdownRetryBackoffMsProp)
+    getLong(KafkaConfig.ControlledShutdownRetryBackoffMsProp)
+  }
+  def controlledShutdownEnable = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ControlledShutdownEnableProp)
+    getBoolean(KafkaConfig.ControlledShutdownEnableProp)
+  }
 
   /** ********* Feature configuration ***********/
   def isFeatureVersioningSupported = interBrokerProtocolVersion.isFeatureVersioningSupported()
 
   /** ********* Group coordinator configuration ***********/
-  val groupMinSessionTimeoutMs = getInt(KafkaConfig.GroupMinSessionTimeoutMsProp)
-  val groupMaxSessionTimeoutMs = getInt(KafkaConfig.GroupMaxSessionTimeoutMsProp)
-  val groupInitialRebalanceDelay = getInt(KafkaConfig.GroupInitialRebalanceDelayMsProp)
-  val groupMaxSize = getInt(KafkaConfig.GroupMaxSizeProp)
+  def groupMinSessionTimeoutMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.GroupMinSessionTimeoutMsProp)
+    getInt(KafkaConfig.GroupMinSessionTimeoutMsProp)
+  }
+  def groupMaxSessionTimeoutMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.GroupMaxSessionTimeoutMsProp)
+    getInt(KafkaConfig.GroupMaxSessionTimeoutMsProp)
+  }
+  def groupInitialRebalanceDelay = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.GroupInitialRebalanceDelayMsProp)
+    getInt(KafkaConfig.GroupInitialRebalanceDelayMsProp)
+  }
+  def groupMaxSize = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.GroupMaxSizeProp)
+    getInt(KafkaConfig.GroupMaxSizeProp)
+  }
 
   /** ********* Offset management configuration ***********/
-  val offsetMetadataMaxSize = getInt(KafkaConfig.OffsetMetadataMaxSizeProp)
-  val offsetsLoadBufferSize = getInt(KafkaConfig.OffsetsLoadBufferSizeProp)
-  val offsetsTopicReplicationFactor = getShort(KafkaConfig.OffsetsTopicReplicationFactorProp)
-  val offsetsTopicPartitions = getInt(KafkaConfig.OffsetsTopicPartitionsProp)
-  val offsetCommitTimeoutMs = getInt(KafkaConfig.OffsetCommitTimeoutMsProp)
-  val offsetCommitRequiredAcks = getShort(KafkaConfig.OffsetCommitRequiredAcksProp)
-  val offsetsTopicSegmentBytes = getInt(KafkaConfig.OffsetsTopicSegmentBytesProp)
-  val offsetsTopicCompressionCodec = Option(getInt(KafkaConfig.OffsetsTopicCompressionCodecProp)).map(value => CompressionCodec.getCompressionCodec(value)).orNull
+  def offsetMetadataMaxSize = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.OffsetMetadataMaxSizeProp)
+    getInt(KafkaConfig.OffsetMetadataMaxSizeProp)
+  }
+  def offsetsLoadBufferSize = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.OffsetsLoadBufferSizeProp)
+    getInt(KafkaConfig.OffsetsLoadBufferSizeProp)
+  }
+  def offsetsTopicReplicationFactor = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.OffsetsTopicReplicationFactorProp)
+    getShort(KafkaConfig.OffsetsTopicReplicationFactorProp)
+  }
+  def offsetsTopicPartitions = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.OffsetsTopicPartitionsProp)
+    getInt(KafkaConfig.OffsetsTopicPartitionsProp)
+  }
+  def offsetCommitTimeoutMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.OffsetCommitTimeoutMsProp)
+    getInt(KafkaConfig.OffsetCommitTimeoutMsProp)
+  }
+  def offsetCommitRequiredAcks = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.OffsetCommitRequiredAcksProp)
+    getShort(KafkaConfig.OffsetCommitRequiredAcksProp)
+  }
+  def offsetsTopicSegmentBytes = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.OffsetsTopicSegmentBytesProp)
+    getInt(KafkaConfig.OffsetsTopicSegmentBytesProp)
+  }
+  def offsetsTopicCompressionCodec = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.OffsetsTopicCompressionCodecProp)
+    Option(getInt(KafkaConfig.OffsetsTopicCompressionCodecProp)).map(value => CompressionCodec.getCompressionCodec(value)).orNull
+  }
 
   /** ********* Transaction management configuration ***********/
-  val transactionalIdExpirationMs = getInt(KafkaConfig.TransactionalIdExpirationMsProp)
-  val transactionMaxTimeoutMs = getInt(KafkaConfig.TransactionsMaxTimeoutMsProp)
-  val transactionTopicMinISR = getInt(KafkaConfig.TransactionsTopicMinISRProp)
-  val transactionsLoadBufferSize = getInt(KafkaConfig.TransactionsLoadBufferSizeProp)
-  val transactionTopicReplicationFactor = getShort(KafkaConfig.TransactionsTopicReplicationFactorProp)
-  val transactionTopicPartitions = getInt(KafkaConfig.TransactionsTopicPartitionsProp)
-  val transactionTopicSegmentBytes = getInt(KafkaConfig.TransactionsTopicSegmentBytesProp)
-  val transactionAbortTimedOutTransactionCleanupIntervalMs = getInt(KafkaConfig.TransactionsAbortTimedOutTransactionCleanupIntervalMsProp)
-  val transactionRemoveExpiredTransactionalIdCleanupIntervalMs = getInt(KafkaConfig.TransactionsRemoveExpiredTransactionalIdCleanupIntervalMsProp)
-
+  def transactionalIdExpirationMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.TransactionalIdExpirationMsProp)
+    getInt(KafkaConfig.TransactionalIdExpirationMsProp)
+  }
+  def transactionMaxTimeoutMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.TransactionsMaxTimeoutMsProp)
+    getInt(KafkaConfig.TransactionsMaxTimeoutMsProp)
+  }
+  def transactionTopicMinISR = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.TransactionsTopicMinISRProp)
+    getInt(KafkaConfig.TransactionsTopicMinISRProp)
+  }
+  def transactionsLoadBufferSize = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.TransactionsLoadBufferSizeProp)
+    getInt(KafkaConfig.TransactionsLoadBufferSizeProp)
+  }
+  def transactionTopicReplicationFactor = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.TransactionsTopicReplicationFactorProp)
+    getShort(KafkaConfig.TransactionsTopicReplicationFactorProp)
+  }
+  def transactionTopicPartitions = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.TransactionsTopicPartitionsProp)
+    getInt(KafkaConfig.TransactionsTopicPartitionsProp)
+  }
+  def transactionTopicSegmentBytes = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.TransactionsTopicSegmentBytesProp)
+    getInt(KafkaConfig.TransactionsTopicSegmentBytesProp)
+  }
+  def transactionAbortTimedOutTransactionCleanupIntervalMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.TransactionsAbortTimedOutTransactionCleanupIntervalMsProp)
+    getInt(KafkaConfig.TransactionsAbortTimedOutTransactionCleanupIntervalMsProp)
+  }
+  def transactionRemoveExpiredTransactionalIdCleanupIntervalMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.TransactionsRemoveExpiredTransactionalIdCleanupIntervalMsProp)
+    getInt(KafkaConfig.TransactionsRemoveExpiredTransactionalIdCleanupIntervalMsProp)
+  }
 
   /** ********* Metric Configuration **************/
-  val metricNumSamples = getInt(KafkaConfig.MetricNumSamplesProp)
-  val metricSampleWindowMs = getLong(KafkaConfig.MetricSampleWindowMsProp)
-  val metricRecordingLevel = getString(KafkaConfig.MetricRecordingLevelProp)
+  def metricNumSamples = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.MetricNumSamplesProp)
+    getInt(KafkaConfig.MetricNumSamplesProp)
+  }
+  def metricSampleWindowMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.MetricSampleWindowMsProp)
+    getLong(KafkaConfig.MetricSampleWindowMsProp)
+  }
+  def metricRecordingLevel = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.MetricRecordingLevelProp)
+    getString(KafkaConfig.MetricRecordingLevelProp)
+  }
 
   /** ********* SSL/SASL Configuration **************/
   // Security configs may be overridden for listeners, so it is not safe to use the base values
   // Hence the base SSL/SASL configs are not fields of KafkaConfig, listener configs should be
   // retrieved using KafkaConfig#valuesWithPrefixOverride
   private def saslEnabledMechanisms(listenerName: ListenerName): Set[String] = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.SaslEnabledMechanismsProp)
     val value = valuesWithPrefixOverride(listenerName.configPrefix).get(KafkaConfig.SaslEnabledMechanismsProp)
     if (value != null)
       value.asInstanceOf[util.List[String]].asScala.toSet
@@ -1876,50 +2351,145 @@ class KafkaConfig private(doLog: Boolean, val props: java.util.Map[_, _], dynami
   def interBrokerSecurityProtocol = getInterBrokerListenerNameAndSecurityProtocol._2
   def controlPlaneListenerName = getControlPlaneListenerNameAndSecurityProtocol.map { case (listenerName, _) => listenerName }
   def controlPlaneSecurityProtocol = getControlPlaneListenerNameAndSecurityProtocol.map { case (_, securityProtocol) => securityProtocol }
-  def saslMechanismInterBrokerProtocol = getString(KafkaConfig.SaslMechanismInterBrokerProtocolProp)
+  def saslMechanismInterBrokerProtocol = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.SaslMechanismInterBrokerProtocolProp)
+    getString(KafkaConfig.SaslMechanismInterBrokerProtocolProp)
+  }
   val saslInterBrokerHandshakeRequestEnable = interBrokerProtocolVersion.isSaslInterBrokerHandshakeRequestEnabled()
 
   /** ********* DelegationToken Configuration **************/
-  val delegationTokenSecretKey = Option(getPassword(KafkaConfig.DelegationTokenSecretKeyProp))
-    .getOrElse(getPassword(KafkaConfig.DelegationTokenSecretKeyAliasProp))
+  def delegationTokenSecretKey = {
+    val result = Option(getPassword(KafkaConfig.DelegationTokenSecretKeyProp))
+    if (result.isEmpty) {
+      logger.info("[CTEST][GET-PARAM] " + KafkaConfig.DelegationTokenSecretKeyAliasProp)
+      getPassword(KafkaConfig.DelegationTokenSecretKeyAliasProp)
+    } else {
+      logger.info("[CTEST][GET-PARAM] " + KafkaConfig.DelegationTokenSecretKeyProp)
+      result.get
+    }
+  }
   val tokenAuthEnabled = (delegationTokenSecretKey != null && !delegationTokenSecretKey.value.isEmpty)
-  val delegationTokenMaxLifeMs = getLong(KafkaConfig.DelegationTokenMaxLifeTimeProp)
-  val delegationTokenExpiryTimeMs = getLong(KafkaConfig.DelegationTokenExpiryTimeMsProp)
-  val delegationTokenExpiryCheckIntervalMs = getLong(KafkaConfig.DelegationTokenExpiryCheckIntervalMsProp)
+  def delegationTokenMaxLifeMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.DelegationTokenMaxLifeTimeProp)
+    getLong(KafkaConfig.DelegationTokenMaxLifeTimeProp)
+  }
+  def delegationTokenExpiryTimeMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.DelegationTokenExpiryTimeMsProp)
+    getLong(KafkaConfig.DelegationTokenExpiryTimeMsProp)
+  }
+  def delegationTokenExpiryCheckIntervalMs = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.DelegationTokenExpiryCheckIntervalMsProp)
+    getLong(KafkaConfig.DelegationTokenExpiryCheckIntervalMsProp)
+  }
 
   /** ********* Password encryption configuration for dynamic configs *********/
-  def passwordEncoderSecret = Option(getPassword(KafkaConfig.PasswordEncoderSecretProp))
-  def passwordEncoderOldSecret = Option(getPassword(KafkaConfig.PasswordEncoderOldSecretProp))
-  def passwordEncoderCipherAlgorithm = getString(KafkaConfig.PasswordEncoderCipherAlgorithmProp)
-  def passwordEncoderKeyFactoryAlgorithm = Option(getString(KafkaConfig.PasswordEncoderKeyFactoryAlgorithmProp))
-  def passwordEncoderKeyLength = getInt(KafkaConfig.PasswordEncoderKeyLengthProp)
-  def passwordEncoderIterations = getInt(KafkaConfig.PasswordEncoderIterationsProp)
+  def passwordEncoderSecret = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.PasswordEncoderSecretProp)
+    Option(getPassword(KafkaConfig.PasswordEncoderSecretProp))
+  }
+  def passwordEncoderOldSecret = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.PasswordEncoderOldSecretProp)
+    Option(getPassword(KafkaConfig.PasswordEncoderOldSecretProp))
+  }
+  def passwordEncoderCipherAlgorithm = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.PasswordEncoderCipherAlgorithmProp)
+    getString(KafkaConfig.PasswordEncoderCipherAlgorithmProp)
+  }
+  def passwordEncoderKeyFactoryAlgorithm = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.PasswordEncoderKeyFactoryAlgorithmProp)
+    Option(getString(KafkaConfig.PasswordEncoderKeyFactoryAlgorithmProp))
+  }
+  def passwordEncoderKeyLength = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.PasswordEncoderKeyLengthProp)
+    getInt(KafkaConfig.PasswordEncoderKeyLengthProp)
+  }
+  def passwordEncoderIterations = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.PasswordEncoderIterationsProp)
+    getInt(KafkaConfig.PasswordEncoderIterationsProp)
+  }
 
   /** ********* Quota Configuration **************/
-  val numQuotaSamples = getInt(KafkaConfig.NumQuotaSamplesProp)
-  val quotaWindowSizeSeconds = getInt(KafkaConfig.QuotaWindowSizeSecondsProp)
-  val numReplicationQuotaSamples = getInt(KafkaConfig.NumReplicationQuotaSamplesProp)
-  val replicationQuotaWindowSizeSeconds = getInt(KafkaConfig.ReplicationQuotaWindowSizeSecondsProp)
-  val numAlterLogDirsReplicationQuotaSamples = getInt(KafkaConfig.NumAlterLogDirsReplicationQuotaSamplesProp)
-  val alterLogDirsReplicationQuotaWindowSizeSeconds = getInt(KafkaConfig.AlterLogDirsReplicationQuotaWindowSizeSecondsProp)
-  val numControllerQuotaSamples = getInt(KafkaConfig.NumControllerQuotaSamplesProp)
-  val controllerQuotaWindowSizeSeconds = getInt(KafkaConfig.ControllerQuotaWindowSizeSecondsProp)
+  def numQuotaSamples = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.NumQuotaSamplesProp)
+    getInt(KafkaConfig.NumQuotaSamplesProp)
+  }
+  def quotaWindowSizeSeconds = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.QuotaWindowSizeSecondsProp)
+    getInt(KafkaConfig.QuotaWindowSizeSecondsProp)
+  }
+  def numReplicationQuotaSamples = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.NumReplicationQuotaSamplesProp)
+    getInt(KafkaConfig.NumReplicationQuotaSamplesProp)
+  }
+  def replicationQuotaWindowSizeSeconds = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ReplicationQuotaWindowSizeSecondsProp)
+    getInt(KafkaConfig.ReplicationQuotaWindowSizeSecondsProp)
+  }
+  def numAlterLogDirsReplicationQuotaSamples = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.NumAlterLogDirsReplicationQuotaSamplesProp)
+    getInt(KafkaConfig.NumAlterLogDirsReplicationQuotaSamplesProp)
+  }
+  def alterLogDirsReplicationQuotaWindowSizeSeconds = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.AlterLogDirsReplicationQuotaWindowSizeSecondsProp)
+    getInt(KafkaConfig.AlterLogDirsReplicationQuotaWindowSizeSecondsProp)
+  }
+  def numControllerQuotaSamples = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.NumControllerQuotaSamplesProp)
+    getInt(KafkaConfig.NumControllerQuotaSamplesProp)
+  }
+  def controllerQuotaWindowSizeSeconds = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ControllerQuotaWindowSizeSecondsProp)
+    getInt(KafkaConfig.ControllerQuotaWindowSizeSecondsProp)
+  }
 
   /** ********* Fetch Configuration **************/
-  val maxIncrementalFetchSessionCacheSlots = getInt(KafkaConfig.MaxIncrementalFetchSessionCacheSlots)
-  val fetchMaxBytes = getInt(KafkaConfig.FetchMaxBytes)
+  def maxIncrementalFetchSessionCacheSlots = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.MaxIncrementalFetchSessionCacheSlots)
+    getInt(KafkaConfig.MaxIncrementalFetchSessionCacheSlots)
+  }
+  def fetchMaxBytes = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.FetchMaxBytes)
+    getInt(KafkaConfig.FetchMaxBytes)
+  }
 
-  val deleteTopicEnable = getBoolean(KafkaConfig.DeleteTopicEnableProp)
-  def compressionType = getString(KafkaConfig.CompressionTypeProp)
+  def deleteTopicEnable = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.DeleteTopicEnableProp)
+    getBoolean(KafkaConfig.DeleteTopicEnableProp)
+  }
+  def compressionType = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.CompressionTypeProp)
+    getString(KafkaConfig.CompressionTypeProp)
+  }
 
   /** ********* Raft Quorum Configuration *********/
-  val quorumVoters = getList(RaftConfig.QUORUM_VOTERS_CONFIG)
-  val quorumElectionTimeoutMs = getInt(RaftConfig.QUORUM_ELECTION_TIMEOUT_MS_CONFIG)
-  val quorumFetchTimeoutMs = getInt(RaftConfig.QUORUM_FETCH_TIMEOUT_MS_CONFIG)
-  val quorumElectionBackoffMs = getInt(RaftConfig.QUORUM_ELECTION_BACKOFF_MAX_MS_CONFIG)
-  val quorumLingerMs = getInt(RaftConfig.QUORUM_LINGER_MS_CONFIG)
-  val quorumRequestTimeoutMs = getInt(RaftConfig.QUORUM_REQUEST_TIMEOUT_MS_CONFIG)
-  val quorumRetryBackoffMs = getInt(RaftConfig.QUORUM_RETRY_BACKOFF_MS_CONFIG)
+  def quorumVoters = {
+    logger.info("[CTEST][GET-PARAM] " + RaftConfig.QUORUM_VOTERS_CONFIG)
+    getList(RaftConfig.QUORUM_VOTERS_CONFIG)
+  }
+  def quorumElectionTimeoutMs = {
+    logger.info("[CTEST][GET-PARAM] " + RaftConfig.QUORUM_ELECTION_TIMEOUT_MS_CONFIG)
+    getInt(RaftConfig.QUORUM_ELECTION_TIMEOUT_MS_CONFIG)
+  }
+  def quorumFetchTimeoutMs = {
+    logger.info("[CTEST][GET-PARAM] " + RaftConfig.QUORUM_FETCH_TIMEOUT_MS_CONFIG)
+    getInt(RaftConfig.QUORUM_FETCH_TIMEOUT_MS_CONFIG)
+  }
+  def quorumElectionBackoffMs = {
+    logger.info("[CTEST][GET-PARAM] " + RaftConfig.QUORUM_ELECTION_BACKOFF_MAX_MS_CONFIG)
+    getInt(RaftConfig.QUORUM_ELECTION_BACKOFF_MAX_MS_CONFIG)
+  }
+  def quorumLingerMs = {
+    logger.info("[CTEST][GET-PARAM] " + RaftConfig.QUORUM_LINGER_MS_CONFIG)
+    getInt(RaftConfig.QUORUM_LINGER_MS_CONFIG)
+  }
+  def quorumRequestTimeoutMs = {
+    logger.info("[CTEST][GET-PARAM] " + RaftConfig.QUORUM_REQUEST_TIMEOUT_MS_CONFIG)
+    getInt(RaftConfig.QUORUM_REQUEST_TIMEOUT_MS_CONFIG)
+  }
+  def quorumRetryBackoffMs = {
+    logger.info("[CTEST][GET-PARAM] " + RaftConfig.QUORUM_RETRY_BACKOFF_MS_CONFIG)
+    getInt(RaftConfig.QUORUM_RETRY_BACKOFF_MS_CONFIG)
+  }
 
   def addReconfigurable(reconfigurable: Reconfigurable): Unit = {
     dynamicConfig.addReconfigurable(reconfigurable)
@@ -1933,12 +2503,22 @@ class KafkaConfig private(doLog: Boolean, val props: java.util.Map[_, _], dynami
     val millisInMinute = 60L * 1000L
     val millisInHour = 60L * millisInMinute
 
-    val millis: java.lang.Long =
-      Option(getLong(KafkaConfig.LogRetentionTimeMillisProp)).getOrElse(
-        Option(getInt(KafkaConfig.LogRetentionTimeMinutesProp)) match {
-          case Some(mins) => millisInMinute * mins
-          case None => getInt(KafkaConfig.LogRetentionTimeHoursProp) * millisInHour
-        })
+    val result = Option(getLong(KafkaConfig.LogRetentionTimeMillisProp))
+    val millis: java.lang.Long = if (result.isEmpty) {
+      Option(getInt(KafkaConfig.LogRetentionTimeMinutesProp)) match {
+        case Some(mins) => {
+          logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogRetentionTimeMinutesProp)
+          millisInMinute * mins
+        }
+        case None => {
+          logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogRetentionTimeHoursProp)
+          getInt(KafkaConfig.LogRetentionTimeHoursProp) * millisInHour
+        }
+      }
+    } else {
+      logger.info("[CTEST][GET-PARAM] " + KafkaConfig.LogRetentionTimeMillisProp)
+      result.get
+    }
 
     if (millis < 0) return -1
     millis
@@ -1956,7 +2536,13 @@ class KafkaConfig private(doLog: Boolean, val props: java.util.Map[_, _], dynami
     CoreUtils.listenerListToEndPoints(getString(KafkaConfig.ListenersProp), effectiveListenerSecurityProtocolMap)
 
   def controllerListenerNames: Seq[String] = {
-    val value = Option(getString(KafkaConfig.ControllerListenerNamesProp)).getOrElse("")
+    val result = Option(getString(KafkaConfig.ControllerListenerNamesProp))
+    val value = if (result.isEmpty) {
+      ""
+    } else {
+      logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ControllerListenerNamesProp)
+      result.get
+    }
     if (value.isEmpty) {
       Seq.empty
     } else {
@@ -1967,7 +2553,10 @@ class KafkaConfig private(doLog: Boolean, val props: java.util.Map[_, _], dynami
   def controllerListeners: Seq[EndPoint] =
     listeners.filter(l => controllerListenerNames.contains(l.listenerName.value()))
 
-  def saslMechanismControllerProtocol: String = getString(KafkaConfig.SaslMechanismControllerProtocolProp)
+  def saslMechanismControllerProtocol: String = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.SaslMechanismControllerProtocolProp)
+    getString(KafkaConfig.SaslMechanismControllerProtocolProp)
+  }
 
   def controlPlaneListener: Option[EndPoint] = {
     controlPlaneListenerName.map { listenerName =>
@@ -1985,6 +2574,7 @@ class KafkaConfig private(doLog: Boolean, val props: java.util.Map[_, _], dynami
 
   // Use advertised listeners if defined, fallback to listeners otherwise
   def effectiveAdvertisedListeners: Seq[EndPoint] = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.AdvertisedListenersProp)
     val advertisedListenersProp = getString(KafkaConfig.AdvertisedListenersProp)
     if (advertisedListenersProp != null)
       CoreUtils.listenerListToEndPoints(advertisedListenersProp, effectiveListenerSecurityProtocolMap, requireDistinctPorts=false)
@@ -1993,6 +2583,8 @@ class KafkaConfig private(doLog: Boolean, val props: java.util.Map[_, _], dynami
   }
 
   private def getInterBrokerListenerNameAndSecurityProtocol: (ListenerName, SecurityProtocol) = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.InterBrokerListenerNameProp)
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.InterBrokerSecurityProtocolProp)
     Option(getString(KafkaConfig.InterBrokerListenerNameProp)) match {
       case Some(_) if originals.containsKey(KafkaConfig.InterBrokerSecurityProtocolProp) =>
         throw new ConfigException(s"Only one of ${KafkaConfig.InterBrokerListenerNameProp} and " +
@@ -2013,6 +2605,7 @@ class KafkaConfig private(doLog: Boolean, val props: java.util.Map[_, _], dynami
   private def getControlPlaneListenerNameAndSecurityProtocol: Option[(ListenerName, SecurityProtocol)] = {
     Option(getString(KafkaConfig.ControlPlaneListenerNameProp)) match {
       case Some(name) =>
+        logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ControlPlaneListenerNameProp)
         val listenerName = ListenerName.normalised(name)
         val securityProtocol = effectiveListenerSecurityProtocolMap.getOrElse(listenerName,
           throw new ConfigException(s"Listener with ${listenerName.value} defined in " +
@@ -2032,6 +2625,7 @@ class KafkaConfig private(doLog: Boolean, val props: java.util.Map[_, _], dynami
   }
 
   def effectiveListenerSecurityProtocolMap: Map[ListenerName, SecurityProtocol] = {
+    logger.info("[CTEST][GET-PARAM] " + KafkaConfig.ListenerSecurityProtocolMapProp)
     val mapValue = getMap(KafkaConfig.ListenerSecurityProtocolMapProp, getString(KafkaConfig.ListenerSecurityProtocolMapProp))
       .map { case (listenerName, protocolName) =>
         ListenerName.normalised(listenerName) -> getSecurityProtocol(protocolName, KafkaConfig.ListenerSecurityProtocolMapProp)
@@ -2256,7 +2850,7 @@ class KafkaConfig private(doLog: Boolean, val props: java.util.Map[_, _], dynami
 
     val principalBuilderClass = getClass(KafkaConfig.PrincipalBuilderClassProp)
     require(principalBuilderClass != null, s"${KafkaConfig.PrincipalBuilderClassProp} must be non-null")
-    require(classOf[KafkaPrincipalSerde].isAssignableFrom(principalBuilderClass), 
+    require(classOf[KafkaPrincipalSerde].isAssignableFrom(principalBuilderClass),
       s"${KafkaConfig.PrincipalBuilderClassProp} must implement KafkaPrincipalSerde")
   }
 }
diff --git a/core/src/main/scala/kafka/server/KafkaServer.scala b/core/src/main/scala/kafka/server/KafkaServer.scala
index 6b52511c1b..106091e219 100755
--- a/core/src/main/scala/kafka/server/KafkaServer.scala
+++ b/core/src/main/scala/kafka/server/KafkaServer.scala
@@ -224,7 +224,7 @@ class KafkaServer(
             s"The broker is trying to join the wrong cluster. Configured zookeeper.connect may be wrong.")
 
         /* generate brokerId */
-        config.brokerId = getOrGenerateBrokerId(preloadedBrokerMetadataCheckpoint)
+        config.setBrokerId(getOrGenerateBrokerId(preloadedBrokerMetadataCheckpoint))
         logContext = new LogContext(s"[KafkaServer id=${config.brokerId}] ")
         this.logIdent = logContext.logPrefix
 
diff --git a/core/src/test/resources/log4j.properties b/core/src/test/resources/log4j.properties
index f7fb7364a3..bee411ab18 100644
--- a/core/src/test/resources/log4j.properties
+++ b/core/src/test/resources/log4j.properties
@@ -12,15 +12,21 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-log4j.rootLogger=OFF, stdout
+log4j.rootLogger=INFO, console
 
 log4j.appender.stdout=org.apache.log4j.ConsoleAppender
 log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
 log4j.appender.stdout.layout.ConversionPattern=[%d] %p %m (%c:%L)%n
 
-log4j.logger.kafka=WARN
-log4j.logger.org.apache.kafka=WARN
+log4j.appender.console=org.apache.log4j.ConsoleAppender
+log4j.appender.console.layout=org.apache.log4j.PatternLayout
+log4j.appender.console.Threshold=DEBUG
+log4j.appender.console.Target=System.out
+log4j.appender.file=org.apache.log4j.RollingFileAppender
+
+log4j.logger.kafka=INFO
+log4j.logger.org.apache.kafka=INFO
 
 
 # zkclient can be verbose, during debugging it is common to adjust it separately
-log4j.logger.org.apache.zookeeper=WARN
+log4j.logger.org.apache.zookeeper=INFO
