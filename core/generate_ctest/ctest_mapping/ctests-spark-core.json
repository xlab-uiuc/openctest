{"spark.broadcast.UDFCompressionThreshold": [], "spark.checkpoint.compress": ["org.apache.spark.CheckpointSuite @ RDDs with one-to-one dependencies [reliable checkpoint]", "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-23207: reliable checkpoint can avoid rollback (checkpointed before)", "org.apache.spark.CheckpointStorageSuite @ SPARK-31484: checkpoint should not fail in retry", "org.apache.spark.CheckpointSuite @ BlockRDD [reliable checkpoint]", "org.apache.spark.CheckpointSuite @ PartitionerAwareUnionRDD [reliable checkpoint]", "org.apache.spark.util.PeriodicRDDCheckpointerSuite @ Checkpointing", "org.apache.spark.CheckpointStorageSuite @ checkpoint compression", "org.apache.spark.CheckpointSuite @ ParallelCollectionRDD [reliable checkpoint]", "org.apache.spark.CheckpointSuite @ CartesianRDD [reliable checkpoint]", "org.apache.spark.CheckpointSuite @ ZippedPartitionsRDD [reliable checkpoint]", "org.apache.spark.CheckpointSuite @ CoGroupedRDD [reliable checkpoint]", "org.apache.spark.CheckpointSuite @ checkpointAllMarkedAncestors [reliable checkpoint]", "org.apache.spark.CheckpointSuite @ UnionRDD [reliable checkpoint]", "org.apache.spark.CheckpointStorageSuite @ cache checkpoint preferred location", "org.apache.spark.CheckpointSuite @ checkpointing partitioners [reliable checkpoint]", "org.apache.spark.CheckpointSuite @ basic checkpointing [reliable checkpoint]", "org.apache.spark.CheckpointSuite @ ShuffleRDD [reliable checkpoint]", "org.apache.spark.CheckpointSuite @ CoalescedRDD [reliable checkpoint]", "org.apache.spark.ContextCleanerSuite @ automatically cleanup normal checkpoint"], "spark.cleaner.referenceTracking.cleanCheckpoints": ["org.apache.spark.CheckpointSuite @ BlockRDD [reliable checkpoint]", "org.apache.spark.CheckpointSuite @ CoalescedRDD [reliable checkpoint]", "org.apache.spark.CheckpointSuite @ PartitionerAwareUnionRDD [reliable checkpoint]", "org.apache.spark.CheckpointStorageSuite @ SPARK-31484: checkpoint should not fail in retry", "org.apache.spark.CheckpointStorageSuite @ cache checkpoint preferred location", "org.apache.spark.CheckpointSuite @ CheckpointRDD with zero partitions [reliable checkpoint]", "org.apache.spark.CheckpointSuite @ checkpointAllMarkedAncestors [reliable checkpoint]", "org.apache.spark.util.PeriodicRDDCheckpointerSuite @ Checkpointing", "org.apache.spark.CheckpointSuite @ ZippedPartitionsRDD [reliable checkpoint]", "org.apache.spark.scheduler.DAGSchedulerSuite @ SPARK-23207: reliable checkpoint can avoid rollback (checkpointed before)", "org.apache.spark.CheckpointStorageSuite @ checkpoint compression", "org.apache.spark.CheckpointSuite @ checkpointing partitioners [reliable checkpoint]", "org.apache.spark.CheckpointSuite @ CoGroupedRDD [reliable checkpoint]", "org.apache.spark.CheckpointSuite @ ShuffleRDD [reliable checkpoint]", "org.apache.spark.CheckpointSuite @ UnionRDD [reliable checkpoint]", "org.apache.spark.CheckpointSuite @ ParallelCollectionRDD [reliable checkpoint]", "org.apache.spark.CheckpointSuite @ RDDs with one-to-one dependencies [reliable checkpoint]", "org.apache.spark.CheckpointSuite @ CartesianRDD [reliable checkpoint]", "org.apache.spark.ContextCleanerSuite @ automatically cleanup normal checkpoint", "org.apache.spark.CheckpointSuite @ basic checkpointing [reliable checkpoint]"], "spark.driver.log.allowErasureCoding": ["org.apache.spark.util.logging.DriverLoggerSuite @ driver logs are persisted locally and synced to dfs"], "spark.driver.userClassPathFirst": ["org.apache.spark.deploy.SparkSubmitSuite @ start SparkApplication without modifying system properties"], "spark.eventLog.dir": ["org.apache.spark.scheduler.EventLoggingListenerSuite @ SPARK-31764: isBarrier should be logged in event log"], "spark.eventLog.logBlockUpdates.enabled": ["org.apache.spark.scheduler.EventLoggingListenerSuite @ SPARK-31764: isBarrier should be logged in event log"], "spark.eventLog.logStageExecutorMetrics": ["org.apache.spark.scheduler.EventLoggingListenerSuite @ SPARK-31764: isBarrier should be logged in event log"], "spark.eventLog.rolling.enabled": [], "spark.eventLog.rolling.maxFileSize": ["org.apache.spark.deploy.history.RollingEventLogFilesWriterSuite @ rolling event log files - codec None", "org.apache.spark.deploy.history.RollingEventLogFilesReaderSuite @ rolling event log files - codec Some(lz4)", "org.apache.spark.deploy.history.RollingEventLogFilesWriterSuite @ rolling event log files - codec Some(snappy)", "org.apache.spark.deploy.history.RollingEventLogFilesReaderSuite @ rolling event log files - codec Some(zstd)", "org.apache.spark.deploy.history.RollingEventLogFilesReaderSuite @ rolling event log files - codec Some(snappy)", "org.apache.spark.deploy.history.RollingEventLogFilesReaderSuite @ rolling event log files - codec None", "org.apache.spark.deploy.history.RollingEventLogFilesWriterSuite @ rolling event log files - codec Some(lz4)", "org.apache.spark.deploy.history.RollingEventLogFilesWriterSuite @ rolling event log files - codec Some(lzf)", "org.apache.spark.deploy.history.RollingEventLogFilesWriterSuite @ rolling event log files - codec Some(zstd)", "org.apache.spark.deploy.history.RollingEventLogFilesReaderSuite @ rolling event log files - codec Some(lzf)", "org.apache.spark.deploy.history.RollingEventLogFilesWriterSuite @ rolling event log files - the max size of event log file size less than lower limit"], "spark.excludeOnFailure.application.maxFailedExecutorsPerNode": ["org.apache.spark.scheduler.HealthTrackerSuite @ executors can be excluded with only a few failures per stage", "org.apache.spark.scheduler.HealthTrackerSuite @ executors aren't excluded as a result of tasks in failed task sets", "org.apache.spark.scheduler.HealthTrackerIntegrationSuite @ SPARK-15865 Progress with fewer executors than maxTaskFailures", "org.apache.spark.scheduler.HealthTrackerSuite @ stage exclude updates correctly on stage failure", "org.apache.spark.scheduler.HealthTrackerSuite @ stage exclude updates correctly on stage success", "org.apache.spark.scheduler.HealthTrackerSuite @ exclude still respects legacy configs", "org.apache.spark.scheduler.TaskSetManagerSuite @ update application healthTracker for shuffle-fetch", "org.apache.spark.scheduler.TaskSetManagerSuite @ update healthTracker before adding pending task to avoid race condition", "org.apache.spark.scheduler.HealthTrackerSuite @ task failures expire with time", "org.apache.spark.scheduler.TaskSchedulerImplSuite @ abort stage if executor loss results in unschedulability from previously failed tasks", "org.apache.spark.scheduler.HealthTrackerSuite @ excluding decommission and kills executors when enabled", "org.apache.spark.scheduler.HealthTrackerSuite @ task failure timeout works as expected for long-running tasksets", "org.apache.spark.deploy.StandaloneDynamicAllocationSuite @ executor registration on a excluded host must fail", "org.apache.spark.scheduler.HealthTrackerSuite @ check exclude configuration invariants"], "spark.excludeOnFailure.application.maxFailedTasksPerExecutor": ["org.apache.spark.scheduler.HealthTrackerSuite @ stage exclude updates correctly on stage failure", "org.apache.spark.scheduler.HealthTrackerSuite @ check exclude configuration invariants", "org.apache.spark.scheduler.TaskSetManagerSuite @ update application healthTracker for shuffle-fetch", "org.apache.spark.scheduler.HealthTrackerSuite @ task failure timeout works as expected for long-running tasksets", "org.apache.spark.scheduler.HealthTrackerSuite @ excluded executors and nodes get recovered with time", "org.apache.spark.scheduler.HealthTrackerIntegrationSuite @ SPARK-15865 Progress with fewer executors than maxTaskFailures", "org.apache.spark.scheduler.HealthTrackerSuite @ exclude still respects legacy configs", "org.apache.spark.scheduler.HealthTrackerSuite @ executors aren't excluded as a result of tasks in failed task sets", "org.apache.spark.scheduler.HealthTrackerSuite @ stage exclude updates correctly on stage success", "org.apache.spark.scheduler.HealthTrackerSuite @ exclude can handle lost executors", "org.apache.spark.scheduler.HealthTrackerSuite @ excluding decommission and kills executors when enabled", "org.apache.spark.scheduler.TaskSetManagerSuite @ update healthTracker before adding pending task to avoid race condition", "org.apache.spark.scheduler.HealthTrackerSuite @ executors can be excluded with only a few failures per stage", "org.apache.spark.deploy.StandaloneDynamicAllocationSuite @ executor registration on a excluded host must fail", "org.apache.spark.scheduler.TaskSchedulerImplSuite @ abort stage if executor loss results in unschedulability from previously failed tasks"], "spark.excludeOnFailure.killExcludedExecutors": ["org.apache.spark.scheduler.HealthTrackerSuite @ excluded executors and nodes get recovered with time", "org.apache.spark.scheduler.HealthTrackerSuite @ stage exclude updates correctly on stage success", "org.apache.spark.scheduler.HealthTrackerSuite @ task failures expire with time", "org.apache.spark.scheduler.TaskSetManagerSuite @ update application healthTracker for shuffle-fetch", "org.apache.spark.scheduler.HealthTrackerSuite @ only exclude nodes for the application when enough executors have failed on that specific host", "org.apache.spark.scheduler.HealthTrackerSuite @ excluding decommission and kills executors when enabled", "org.apache.spark.scheduler.HealthTrackerSuite @ executors can be excluded with only a few failures per stage", "org.apache.spark.scheduler.HealthTrackerSuite @ exclude can handle lost executors"], "spark.excludeOnFailure.timeout": ["org.apache.spark.scheduler.HealthTrackerSuite @ executors can be excluded with only a few failures per stage", "org.apache.spark.deploy.StandaloneDynamicAllocationSuite @ executor registration on a excluded host must fail", "org.apache.spark.scheduler.HealthTrackerSuite @ only exclude nodes for the application when enough executors have failed on that specific host", "org.apache.spark.scheduler.HealthTrackerSuite @ task failures expire with time", "org.apache.spark.scheduler.HealthTrackerSuite @ excluded executors and nodes get recovered with time", "org.apache.spark.scheduler.HealthTrackerSuite @ exclude can handle lost executors", "org.apache.spark.scheduler.HealthTrackerSuite @ stage exclude updates correctly on stage failure", "org.apache.spark.scheduler.HealthTrackerSuite @ executors aren't excluded as a result of tasks in failed task sets", "org.apache.spark.scheduler.HealthTrackerSuite @ stage exclude updates correctly on stage success", "org.apache.spark.scheduler.HealthTrackerSuite @ excluding decommission and kills executors when enabled", "org.apache.spark.scheduler.HealthTrackerIntegrationSuite @ SPARK-15865 Progress with fewer executors than maxTaskFailures", "org.apache.spark.scheduler.HealthTrackerSuite @ task failure timeout works as expected for long-running tasksets", "org.apache.spark.scheduler.HealthTrackerSuite @ check exclude configuration invariants", "org.apache.spark.scheduler.TaskSetManagerSuite @ update application healthTracker for shuffle-fetch", "org.apache.spark.scheduler.TaskSetManagerSuite @ update healthTracker before adding pending task to avoid race condition", "org.apache.spark.scheduler.TaskSchedulerImplSuite @ abort stage if executor loss results in unschedulability from previously failed tasks"], "spark.executor.logs.rolling.enableCompression": ["org.apache.spark.util.FileAppenderSuite @ rolling file appender - time-based rolling", "org.apache.spark.util.FileAppenderSuite @ rolling file appender - time-based rolling (compressed)", "org.apache.spark.util.FileAppenderSuite @ rolling file appender - size-based rolling (compressed)", "org.apache.spark.util.FileAppenderSuite @ rolling file appender - cleaning", "org.apache.spark.util.FileAppenderSuite @ SPARK-35027: rolling file appender - time-based rolling close stream", "org.apache.spark.util.FileAppenderSuite @ file appender selection", "org.apache.spark.util.FileAppenderSuite @ SPARK-35027: rolling file appender - size-based rolling close stream", "org.apache.spark.util.FileAppenderSuite @ rolling file appender - size-based rolling"], "spark.files.overwrite": ["org.apache.spark.deploy.SparkSubmitSuite @ SPARK-21568 ConsoleProgressBar should be enabled only in shells", "org.apache.spark.SparkContextSuite @ cannot call addFile with different paths that have the same filename", "org.apache.spark.deploy.SparkSubmitSuite @ download remote resource if it is not supported by yarn service", "org.apache.spark.SparkContextSuite @ SPARK-33530: basic case for addArchive and listArchives", "org.apache.spark.SparkContextSuite @ addFile can be called twice with same file in non-local-mode (SPARK-16787)", "org.apache.spark.deploy.SparkSubmitSuite @ downloadFile - invalid url", "org.apache.spark.SparkContextSuite @ SPARK-30126: addFile when file path contains spaces with recursive works", "org.apache.spark.deploy.SparkSubmitSuite @ force download from forced schemes", "org.apache.spark.deploy.SparkSubmitSuite @ downloadFile - file doesn't exist", "org.apache.spark.SparkContextSuite @ addFile recursive works", "org.apache.spark.SparkContextSuite @ SPARK-35691: addFile/addJar/addDirectory should put CanonicalFile", "org.apache.spark.deploy.SparkSubmitSuite @ Avoid re-upload remote resources in yarn client mode", "org.apache.spark.SparkContextSuite @ SPARK-30126: addFile when file path contains spaces without recursive works", "org.apache.spark.rpc.netty.NettyRpcEnvSuite @ file server", "org.apache.spark.deploy.SparkSubmitSuite @ download one file to local", "org.apache.spark.deploy.SparkSubmitSuite @ force download for all the schemes", "org.apache.spark.deploy.SparkSubmitSuite @ error informatively when mainClass isn't set and S3 JAR doesn't exist", "org.apache.spark.deploy.SparkSubmitSuite @ support --py-files/spark.submit.pyFiles in non pyspark application", "org.apache.spark.SparkContextSuite @ addFile can be called twice with same file in local-mode (SPARK-16787)", "org.apache.spark.deploy.SparkSubmitSuite @ avoid downloading remote resource if it is supported by yarn service", "org.apache.spark.SparkContextSuite @ basic case for addFile and listFiles", "org.apache.spark.deploy.SparkSubmitSuite @ automatically sets mainClass if primary resource is S3 JAR in client mode", "org.apache.spark.SparkContextSuite @ SPARK-34225: addFile/addJar shouldn't further encode URI if a URI form string is passed", "org.apache.spark.deploy.SparkSubmitSuite @ download list of files to local"], "spark.files.useFetchCache": ["org.apache.spark.rpc.netty.NettyRpcEnvSuite @ file server", "org.apache.spark.SparkContextSuite @ addFile recursive works", "org.apache.spark.SparkContextSuite @ SPARK-30126: addFile when file path contains spaces without recursive works", "org.apache.spark.SparkContextSuite @ SPARK-30126: addFile when file path contains spaces with recursive works", "org.apache.spark.SparkContextSuite @ SPARK-34225: addFile/addJar shouldn't further encode URI if a URI form string is passed", "org.apache.spark.SparkContextSuite @ addFile can be called twice with same file in local-mode (SPARK-16787)", "org.apache.spark.SparkContextSuite @ SPARK-35691: addFile/addJar/addDirectory should put CanonicalFile", "org.apache.spark.SparkContextSuite @ SPARK-33530: basic case for addArchive and listArchives", "org.apache.spark.SparkContextSuite @ addFile can be called twice with same file in non-local-mode (SPARK-16787)", "org.apache.spark.deploy.SparkSubmitSuite @ SPARK-21568 ConsoleProgressBar should be enabled only in shells", "org.apache.spark.SparkContextSuite @ basic case for addFile and listFiles", "org.apache.spark.SparkContextSuite @ cannot call addFile with different paths that have the same filename"], "spark.scheduler.excludeOnFailure.unschedulableTaskSetTimeout": ["org.apache.spark.scheduler.TaskSchedulerImplSuite @ SPARK-22148 abort timer should kick in when task is completely excluded & no new executor can be acquired", "org.apache.spark.scheduler.TaskSchedulerImplSuite @ SPARK-22148 abort timer should clear unschedulableTaskSetToExpiryTime for all TaskSets", "org.apache.spark.scheduler.HealthTrackerIntegrationSuite @ SPARK-15865 Progress with fewer executors than maxTaskFailures", "org.apache.spark.scheduler.TaskSchedulerImplSuite @ SPARK-22148 try to acquire a new executor when task is unschedulable with 1 executor"], "spark.shuffle.accurateBlockThreshold": ["org.apache.spark.serializer.KryoSerializerSuite @ registration of HighlyCompressedMapStatus", "org.apache.spark.serializer.UnsafeKryoSerializerSuite @ registration of HighlyCompressedMapStatus", "org.apache.spark.rdd.RDDSuite @ collect large number of empty partitions", "org.apache.spark.scheduler.MapStatusSuite @ SPARK-22540: ensure HighlyCompressedMapStatus calculates correct avgSize"], "spark.shuffle.io.maxRetries": ["org.apache.spark.DistributedSuite @ caching (encryption = off)", "org.apache.spark.rdd.PairRDDFunctionsSuite @ sampleByKey", "org.apache.spark.scheduler.SparkListenerSuite @ onTaskGettingResult() called when result fetched remotely", "org.apache.spark.network.netty.NettyBlockTransferSecuritySuite @ security on mismatch password", "org.apache.spark.StatusTrackerSuite @ getJobIdsForGroup()", "org.apache.spark.rdd.PairRDDFunctionsSuite @ sampleByKeyExact", "org.apache.spark.network.netty.NettyBlockTransferSecuritySuite @ security mismatch auth off on client", "org.apache.spark.network.netty.NettyBlockTransferSecuritySuite @ security mismatch auth off on server", "org.apache.spark.scheduler.TaskResultGetterSuite @ handling results larger than max RPC message size", "org.apache.spark.rdd.DoubleRDDSuite @ WorksWithHugeRange", "org.apache.spark.storage.BlockManagerSuite @ SPARK-9591: getRemoteBytes from another location when Exception throw", "org.apache.spark.DistributedSuite @ caching on disk (encryption = off)", "org.apache.spark.storage.BlockManagerSuite @ SPARK-17484: master block locations are updated following an invalid remote block fetch", "org.apache.spark.network.netty.NettyBlockTransferSecuritySuite @ security default off", "org.apache.spark.DistributedSuite @ caching (encryption = on)", "org.apache.spark.scheduler.TaskSetManagerSuite @ abort the job if total size of results is too large", "org.apache.spark.network.netty.NettyBlockTransferServiceSuite @ SPARK-27637: test fetch block with executor dead", "org.apache.spark.storage.BlockManagerSuite @ SPARK-14252: getOrElseUpdate should still read from remote storage", "org.apache.spark.network.netty.NettyBlockTransferSecuritySuite @ security with aes encryption", "org.apache.spark.scheduler.TaskResultGetterSuite @ task retried if result missing from block manager", "org.apache.spark.DistributedSuite @ caching on disk (encryption = on)", "org.apache.spark.rdd.RDDSuite @ takeSample", "org.apache.spark.serializer.KryoSerializerResizableOutputSuite @ kryo with resizable output buffer should succeed on large array", "org.apache.spark.network.netty.NettyBlockTransferSecuritySuite @ security on same password"], "spark.shuffle.registration.maxAttempts": ["org.apache.spark.storage.BlockManagerSuite @ SPARK-20640: Shuffle registration timeout and maxAttempts conf are working"], "spark.storage.decommission.fallbackStorage.cleanUp": ["org.apache.spark.storage.FallbackStorageSuite @ zstd - Newly added executors should access old data from remote storage", "org.apache.spark.storage.FallbackStorageSuite @ snappy - Newly added executors should access old data from remote storage", "org.apache.spark.storage.FallbackStorageSuite @ Upload multi stages", "org.apache.spark.storage.FallbackStorageSuite @ lz4 - Newly added executors should access old data from remote storage", "org.apache.spark.storage.FallbackStorageSuite @ SPARK-34142: fallback storage API - cleanUp", "org.apache.spark.storage.FallbackStorageSuite @ Upload from all decommissioned executors", "org.apache.spark.storage.FallbackStorageSuite @ lzf - Newly added executors should access old data from remote storage"], "spark.storage.decommission.rddBlocks.enabled": ["org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ block decom manager with only shuffle files time moves forward", "org.apache.spark.storage.FallbackStorageSuite @ migrate shuffle data to fallback storage", "org.apache.spark.storage.BlockManagerSuite @ SPARK-33387 Support ordered shuffle block migration", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ block decom manager handles IO failures", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ block decom manager with no migrations configured", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ test shuffle and cached rdd migration without any error", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ block decom manager does not re-add removed shuffle files", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ block decom manager with no peers", "org.apache.spark.storage.BlockManagerSuite @ test decommissionRddCacheBlocks should keep the block if it is not able to migrate", "org.apache.spark.storage.BlockManagerSuite @ test migration of shuffle blocks during decommissioning - no limit", "org.apache.spark.storage.BlockManagerSuite @ test migration of shuffle blocks during decommissioning - larger limit", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ test that with no blocks we finish migration", "org.apache.spark.storage.BlockManagerSuite @ test decommissionRddCacheBlocks should migrate all cached blocks", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ block decom manager short circuits removed blocks", "org.apache.spark.storage.BlockManagerSuite @ [SPARK-34363]test migration of shuffle blocks during decommissioning - small limit"], "spark.storage.decommission.shuffleBlocks.enabled": ["org.apache.spark.storage.BlockManagerSuite @ test migration of shuffle blocks during decommissioning - larger limit", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ test that with no blocks we finish migration", "org.apache.spark.storage.BlockManagerSuite @ SPARK-33387 Support ordered shuffle block migration", "org.apache.spark.storage.BlockManagerSuite @ test decommissionRddCacheBlocks should keep the block if it is not able to migrate", "org.apache.spark.storage.BlockManagerSuite @ [SPARK-34363]test migration of shuffle blocks during decommissioning - small limit", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ block decom manager with no peers", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ block decom manager does not re-add removed shuffle files", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ block decom manager with only shuffle files time moves forward", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ block decom manager short circuits removed blocks", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ block decom manager with no migrations configured", "org.apache.spark.storage.BlockManagerSuite @ test migration of shuffle blocks during decommissioning - no limit", "org.apache.spark.storage.FallbackStorageSuite @ migrate shuffle data to fallback storage", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ block decom manager handles IO failures", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ test shuffle and cached rdd migration without any error", "org.apache.spark.storage.BlockManagerSuite @ test decommissionRddCacheBlocks should migrate all cached blocks"], "spark.storage.decommission.shuffleBlocks.maxThreads": ["org.apache.spark.storage.BlockManagerSuite @ test migration of shuffle blocks during decommissioning - no limit", "org.apache.spark.storage.BlockManagerSuite @ [SPARK-34363]test migration of shuffle blocks during decommissioning - small limit", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ block decom manager does not re-add removed shuffle files", "org.apache.spark.storage.BlockManagerSuite @ test decommissionRddCacheBlocks should migrate all cached blocks", "org.apache.spark.storage.FallbackStorageSuite @ migrate shuffle data to fallback storage", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ test that with no blocks we finish migration", "org.apache.spark.storage.BlockManagerSuite @ test migration of shuffle blocks during decommissioning - larger limit", "org.apache.spark.storage.BlockManagerSuite @ test decommissionRddCacheBlocks should keep the block if it is not able to migrate", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ block decom manager with no peers", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ block decom manager short circuits removed blocks", "org.apache.spark.storage.BlockManagerSuite @ SPARK-33387 Support ordered shuffle block migration", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ block decom manager handles IO failures", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ test shuffle and cached rdd migration without any error", "org.apache.spark.storage.BlockManagerDecommissionUnitSuite @ block decom manager with only shuffle files time moves forward"]}